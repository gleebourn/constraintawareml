#!/usr/bin/env python
from pickle import dump
from numpy import geomspace
from jax.numpy import inf,array,array_split,zeros,sum as jsm,\
                      exp,zeros,ones,asarray,maximum,minimum,log
from jax.lax import dot_general,scan
from jax.random import key,split,normal
from jax import jit,value_and_grad,grad,vmap
from jaxlib.xla_extension import XlaRuntimeError
from jax.tree import map as jma,reduce as jrd
from jax.nn import tanh
from sys import path,stdin
from os import mkdir,environ,get_terminal_size
from itertools import count
from pathlib import Path
from collections import namedtuple
from os.path import dirname,abspath
from sys import path
path.append(dirname(dirname(abspath(__file__))))
from cal.thlay import activations,f_to_str,shuffle_xy,init_layers,upd_adam,show_unique_stats,\
                      mk_epochs,mk_exps,rbd24,report_epochs,plot_epochs,update_epoch_history,\
                      ewma,mk_soft_cross_entropy,implementation,TimeStepper,KeyEmitter,l2,mk_l1,\
                      mk_l2,upd_grad,gts

act_name='relu'#'tanh'
initialisation='glorot_normal' if act_name=='relu' else 'glorot_uniform'
ts=TimeStepper(clock_avg_rate=.1)
ke=KeyEmitter(1729)
act=activations['relu']
imp=implementation('mlp',act)
bs=128
#bs=32

sds='P2P_smartphone' #sds=''

(X_train,Y_train),(X_test,Y_test),(_,X_columns)=rbd24(rescale_log=True,preproc=True,
                                                       categorical=True,single_dataset=sds)
n_batches=len(Y_train)//bs
p_train=Y_train.mean()
p_test=Y_test.mean()
in_dim=len(X_train[0])

n_starts=4
n_ends=4
target_fpfns=[(.05,.025)]
targ_fpfns=[a/b for a,b in target_fpfns]
#start_dims=geomspace(32,64,n_starts)
#end_dims=geomspace(4,16,n_ends)
start_dims=[128]
end_dims=[16]
#lrs=[1e-4*(10**i) for i in range(3)]
#regs=[1e-2*2**i for i in range(3)]
lrs=[1e-3]#,1e-4,1e-5]
regs=[1e-2]#,1e-2]
depths=[2]
beta2s=[.999]
#lrbets=[.2,.1,.05]#[.2,.5]
#pids=[{'p':a,'i':b,'d':c} for a in geomspace(.001,.1,4) for b in geomspace(.001,.1,4) for\
#      c in geomspace(.001,.1,4)]

exps=mk_exps(targ_fpfns,in_dim,initialisation,p_train,ke.emit_key(),tfpfns=target_fpfns,pids=pids,
             beta2s=beta2s,lrs=lrs,regs=regs,start_dims=start_dims,end_dims=end_dims,depths=depths)
states=[e['state'] for e in exps]
consts=[e['const'] for e in exps]
shapes=[e['shape'] for e in exps]
print(len(exps),len(states),len(consts))
print('n experiments:',len(exps))
  
outf=Path('jj.pkl')

def mk_surrogate(imp,reg=None,p=p_train):
  imb=p_train/(1-p_train)
  @jit
  def surrogate(w,x,y,U,V,eps): #U=beta**2, V=1
    yp=(1+imp(w,x))/2
    #return (-(y*log(eps+yp))+(~y)*log(U**2*(p_train/(1-p_train))+yp)).sum()
    return ((-1)**y*log(eps+(~y)*imb*V/U+yp)).sum()
  return surrogate

#epochs=mk_epochs(imp,n_batches,bs,mk_surrogate(imp),mk_beta=lambda p,tfp,tfn:1+(tfp-tfn)/p)
epochs=mk_epochs(imp,n_batches,bs,mk_soft_cross_entropy(imp,reg=False),tune_pid=True)

term_size=gts()
epochs_per_report=10
for step in count():
  ts.get_timestep('start')
  states,l2_states,consts,recent_benches=epochs(states,consts,X_train,Y_train,X_test,Y_test,
                                         ke.emit_key(epochs_per_report))
  ts.get_timestep('epochs')
  print('epoch',step*epochs_per_report)
  print('p_train,p_test:',p_train,p_test)
  print(show_unique_stats([{**s,**b,**c,'shape':sh} for s,c,b,sh in\
                           zip(l2_states,consts,benches,
                               ['->'.join([str(s) for s in sh]) for sh in shapes])],
                           trunc=True,by='div',prec=4,term_size=term_size,ts=ts),
        flush=True)
  ts.get_timestep('rep_states')
  ts.report(p=True)
  step+=1
  #change_worst(states,consts,benches,shapes,2,ke.emit_key())
  ts.get_timestep('chnge_wrst')
  with outf.open('wb') as fd:
    dump((states,consts,shapes,epochs_per_report*step,ke.parents),fd)
  ts.get_timestep('save')
