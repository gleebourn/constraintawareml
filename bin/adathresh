#!/usr/bin/env python
from pickle import dump
from numpy import geomspace
from jax.numpy import inf,array,array_split,zeros,sum as jsm,\
                      exp,zeros,ones,asarray,maximum,minimum,log
from jax.lax import dot_general,scan
from jax.random import key,split,normal,binomial
from jax import jit,value_and_grad,grad,vmap,devices
from jaxlib.xla_extension import XlaRuntimeError
from jax.tree import map as jma,reduce as jrd
from sys import path,stdin
from os import mkdir,environ,get_terminal_size
from itertools import count
from pathlib import Path
from collections import namedtuple
from os.path import dirname,abspath
from sys import path
from csv import writer
path.append(dirname(dirname(abspath(__file__))))
from cal.thlay import activations,f_to_str,shuffle_xy,init_layers_adam,dict_adam_no_bias,\
                      rbd24,mk_cross_entropy,implementation,TimeStepper,KeyEmitter,l2,mk_l1,\
                      mk_l2,dict_grad,mk_hinge,unsw,find_thresh,ewma,forward

#act_name='tanh'
act_name='relu'
act=activations[act_name]
init='glorot_normal' if act_name=='relu' else 'glorot_uniform'
ts=TimeStepper(clock_avg_rate=.1)
ke=KeyEmitter(1729)
act=activations[act_name]
bs=128
sds='P2P_smartphone' #sds=''

dataset='unsw'
#dataset='rbd24'
batchnorm=False
#batchnorm=True

if dataset=='unsw':
  (X_trn,Y_trn),(X_tst,Y_tst),_,sc=unsw(rescale='standard',verbose=False)#numeric_only=True,
else:
  (X_trn,Y_trn),(X_tst,Y_tst),(_,sc)=rbd24(rescale='standard',preproc=True,
                                           categorical=True,single_dataset=sds)

n_batches=len(Y_trn)//bs
last=n_batches*bs#-(len(Y_trn)%bs)
last=n_batches*bs
p_trn=Y_trn.mean()
p_tst=Y_tst.mean()
in_dim=len(X_trn[0])
t=0

_forward=lambda w,x:forward(w,x,act,batchnorm=batchnorm,transpose=True)
#def _forward(w,x):
#  for a,b in w[:-1]:
#    x=act(x@a+b)
#  return x@w[-1][0]+w[-1][1]

def _loss(w,x,y,bet):
  yp=_forward(w,x)
  #return -jsm((bet*y+(1-y)/bet)*log(1+1e-4+(2*y-1)*act(yp)))#-.5*log(yp.var())
  #return jsm(act((bet*y+(1-y)/bet)*(1-2*y)*yp))
  #return jsm(maximum(0,(bet*y+(1-y)/bet)*(1-2*y)*yp))
  return jsm((bet*y+(1-y)/bet)*(1-2*y)*yp)

_dl=grad(_loss)
n_par=8
#consts_bet=dict(lrfpfn=geomspace(.001,.015,n_par),tfp=array([.1]*n_par),tfn=array([.1]*n_par))
def _upd(x,y,s,ca,cb):
  return dict_adam_no_bias(_dl(s['w'],x,y,cb['bet']),s,ca)
  #return dict_grad(_dl(s['w'],x,y,bet),s,c)

def _set_bet(cb,pred,epoch,ep_scale):
  cb['bet']*=exp(cb['lrfpfn']*(-pred['fp_trn']/cb['tfp']+pred['fn_trn']/cb['tfn'])/epoch**ep_scale)
  return cb

f=vmap(_forward,(0,None),0)
loss=vmap(_loss,(0,None,None,0),0)
dl=vmap(_dl,(0,None,None,0),0)
upd=vmap(_upd,(None,None,0,0,0),0)
set_bet=vmap(_set_bet,(0,0,None,None),0)#,None

@jit
def steps(states,consts_adam,X,Y,consts_bet):
  return scan(lambda states,xy:(upd(xy[0],xy[1],states,consts_adam,consts_bet),0),states,(X,Y))[0]

@jit
def get_reshuffled(k):
  X,Y=shuffle_xy(k,X_trn,Y_trn)
  return X[:last].reshape(n_batches,bs,-1),Y[:last].reshape(n_batches,bs)


@jit
def _get_preds(w,X_trn,Y_trn,X_tst,Y_tst):#,tfpfn):
  yps=forward(w,X_trn,act,transpose=True,get_transform=batchnorm,batchnorm=batchnorm)
  if batchnorm:
    yps,w=yps
  Yp_smooth_trn=yps.flatten()
  Yp_smooth_tst=forward(w,X_tst,act,transpose=True,batchnorm=False).flatten()
  Yp_trn=Yp_smooth_trn>0.
  Yp_tst=Yp_smooth_tst>0.
  #y_max=Yp_smooth_trn.max()
  #y_min=Yp_smooth_trn.min()
  return {'fp_trn':((~Y_trn)&(Yp_trn)).mean(),'fn_trn':((Y_trn)&(~Yp_trn)).mean(),
          'fp_tst':((~Y_tst)&(Yp_tst)).mean(),'fn_tst':((Y_tst)&(~Yp_tst)).mean()}#,
          #'max':y_max,'min':y_min,'var':Yp_smooth_trn.var()}

@jit
def _get_preds_thresh(w,X_trn,Y_trn,X_tst,Y_tst,tfpfn):
  yps=forward(w,X_trn,act,transpose=True,get_transform=batchnorm,batchnorm=batchnorm)
  if batchnorm:
    yps,w=yps
  Yp_smooth_trn=yps.flatten()
  Yp_smooth_tst=forward(w,X_tst,act,transpose=True,batchnorm=False).flatten()
  Yp_trn=Yp_smooth_trn>0.
  Yp_tst=Yp_smooth_tst>0.
  y_max=Yp_smooth_trn.max()
  y_min=Yp_smooth_trn.min()
  thresh=find_thresh(Y_trn,Yp_smooth_trn,tfpfn,1e-1)
  Yp_trn_thresh=Yp_smooth_trn>thresh
  return {'fp_trn':((~Y_trn)&(Yp_trn)).mean(),'fn_trn':((Y_trn)&(~Yp_trn)).mean(),
          'fp_tst':((~Y_tst)&(Yp_tst)).mean(),'fn_tst':((Y_tst)&(~Yp_tst)).mean(),
          'fp_tsh':((~Y_trn)&(Yp_trn_thresh)).mean(),'fn_tsh':((Y_trn)&(~Yp_trn_thresh)).mean(),
          'max':y_max,'min':y_min,'var':Yp_smooth_trn.var(),'thresh':thresh}

@jit
def _get_state(s):
  return dict(wl2=l2(s['w']),mv=l2(s['m'])/l2(s['v']),t=s['t'])

get_preds=vmap(_get_preds,(0,None,None,None,None),0)
get_preds_thresh=vmap(_get_preds_thresh,(0,None,None,None,None,0),0)
get_state=vmap(_get_state)
mod_shape=[in_dim,128,64,32,1]#[in_dim,1]
##mod_shape=[in_dim,256,128,64,1]#,8,1]#[in_dim,1]
##mod_shape=[in_dim,81, 54, 36, 24, 16,1]#,256,128,64,1]#,8,1]#[in_dim,1]
#mod_shape=[in_dim,54,36,24,16,1]#,256,128,64,1]#,8,1]#[in_dim,1]
#start_width=64
#end_width=8
#depth=8
#width_decay=(end_width/start_width)**(1/depth)
#mod_shape=[in_dim]+[int(start_width*width_decay**i) for i in range(depth)]+[1]
print('Model shape:',mod_shape)


ep_scale=0.
epochs_per_trial=200

out='n_ep_'+str(epochs_per_trial)+'_'+act_name+'_'+dataset+('-'.join([str(l) for l in mod_shape]))

outp=out+'.pkl'
outc=out+'.csv'
outc_nice=out+'_rounded.csv'

if batchnorm:
  outp='bn_'+outp
  outc='bn_'+outc
  outc_nice='bn_'+outc_nice

outp=Path(outp)
outc=Path(outc)
outc_nice=Path(outc_nice)

ts.get_timestep()
epoch_keys=ke.emit_key(epochs_per_trial)
state_key=ke.emit_key()
res={}
tfps=geomspace(.1,.5,n_par)
tfns=geomspace(.1,.01,n_par)

lrs=[.0001]
#lrs=[.001]#,.00001,.000001]
tfpfn=array(tfps/tfns)
#lrfpfns=geomspace(.0001,.001,10)
lrfpfns=geomspace(.0002,.03,10)
#lrfpfns=geomspace(.0001,.1,10)#[.0003,.003,.01]
regs=[.001,.01]#[1,.3,.1]#,.001]#,.0001,0]#[.1,.01,.001]#geomspace(.0001,.01,5)
#[lr,reg*lr,lrfpfn,tfp,tfn,fp_train,fn_train,fp_test,fn_test]
header='lr,reg,lrfpfn,tfp,tfn,fp_train,fn_train,fp_test,fn_test\n'
with outc.open('w') as fd:fd.write(header)
with outc_nice.open('w') as fd:fd.write(header)
for lrfpfn,reg,lr in [(lrfpfn,reg,lr) for lrfpfn in lrfpfns for reg in regs for lr in lrs]:
  res_current=dict(fp_trn=[],fn_trn=[],fp_tst=[],fn_tst=[])
  res[lrfpfn,reg*lr,lr]=res_current
  consts_bet=dict(lrfpfn=array([lrfpfn]*n_par),
                  tfp=array(tfps),
                  bet=array([((1-p_trn)/p_trn)**.5]*n_par),
                  tfn=array(tfns))
  consts_adam=dict(beta1=array([.9]*n_par),beta2=array([.999]*n_par),lr=array([lr]*n_par),
                   reg=array([reg*lr]*n_par),eps=array([1e-8]*n_par))
  states=init_layers_adam(mod_shape,init,k=state_key,transpose=True,n=n_par,bias=.1)
  for epoch,k in enumerate(epoch_keys,1):
    X,Y=get_reshuffled(k)
    ts.get_timestep('shuffle')
    states=steps(states,consts_adam,X,Y,consts_bet)
    ts.get_timestep('epoch')
    preds=get_preds_thresh(states['w'],X_trn,Y_trn,X_tst,Y_tst,tfpfn)
    #preds=get_preds(states['w'],X_trn,Y_trn,X_tst,Y_tst)#,tfpfn)
    ts.get_timestep('pred')
    [v.append(preds[l]) for l,v in res_current.items()]
    ts.get_timestep('record')
    states['w'][-1][1]-=preds['thresh'].reshape(-1,1)#*.2
    ts.get_timestep('upd_thr')
    consts_bet=set_bet(consts_bet,preds,epoch,ep_scale)
    ts.get_timestep('upd_bet')
    if not epoch%10:
      print('============','epoch',epoch,'============')
      #f_to_str(['l_last']+list(loss(states['w'],X[0],Y[0],consts_bet['bet'])),p=True)
      l2stats=get_state(states)
      ts.get_timestep('l2s')
      [f_to_str([v]+list(l2stats[v]),p=True) for\
       v in sorted(list(l2stats),key=lambda s:s[-2:]=='l2' and s[0]!='w')]
      [f_to_str([v]+list(consts_bet[v]),p=True) for v in consts_bet]
      [f_to_str([v]+list(consts_adam[v]),p=True) for v in ['lr','reg']]
      [f_to_str([pr]+list(preds[pr]),p=True) for\
       pr in sorted(list(preds),key=lambda s:s[-3:]=='trn')]
      ts.get_timestep('report')
      ts.report(p=True)

  with outp.open('wb') as fd:
    dump((tfps,tfns,res,mod_shape),fd)
  with outc.open('a') as fd:
    with outc_nice.open('a') as fd_nice:
      w=writer(fd)
      w_nice=writer(fd_nice)
      fp_trains=res_current['fp_trn'][-1]
      fn_trains=res_current['fn_trn'][-1]
      fp_tests=res_current['fp_tst'][-1]
      fn_tests=res_current['fn_tst'][-1]
      for tfp,tfn,fp_train,fn_train,fp_test,fn_test in\
      zip(tfps,tfns,fp_trains,fn_trains,fp_tests,fn_tests):
        row=[lr,reg*lr,lrfpfn,tfp,tfn,fp_train,fn_train,fp_test,fn_test]
        w.writerow(row)
        w_nice.writerow([f_to_str(z) for z in row])
