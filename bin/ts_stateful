#!/usr/bin/env python
#from pickle import load,dump
#from time import perf_counter
from jax.numpy import zeros,sum as jsm,concatenate,isfinite,\
                      array,size,array_split,exp,log,maximum,signbit
from jax.random import key,split,randint
from jax import jit,value_and_grad
from sys import path,stdin
from os import mkdir,environ
from os.path import dirname,abspath
from sys import path
path.append(dirname(dirname(abspath(__file__))))
from cal.thlay import rbd24,init_layers,read_input_if_ready,\
                      TimeStepper,OTFBinWeights,activations,\
                      implementation,select_initialisation,\
                      upd_adam,set_jax_cache,l2,dl2

set_jax_cache()
k=key(1729)

(x_r,y_r),(x_e,y_e),\
(_,x_columns)=rbd24(rescale_log=True,preproc=True,categorical=True)

n_r,x_dim=x_r.shape
n_e=len(x_e)

p_r=jsm(y_r)/len(y_r)
p_e=jsm(y_e)/len(y_e)
print('Train imbalance:',p_r)
print('Test imbalance:',p_e)

state_dim=16
in_dim=x_dim+state_dim

expansion_factor=1
predict_layers=5

predict_dims=[in_dim]+[int((expansion_factor*in_dim)**(1-i/predict_layers)*\
                           (state_dim**(i/predict_layers))) for\
                       i in range(predict_layers+1)]

imp='mlp'
act='relu'#'tanh'
activation=activations[act]
forward=implementation(imp,activation)
init=select_initialisation(imp,act)
w=init_layers(k,predict_dims,init)
v=[a*0. for a in w[0]],[b*0 for b in w[1]]
m=0.
print(predict_dims)
print([a.shape for a in w[0]])
print([b.shape for b in w[1]])

@jit
def predict(w,s,X):
  n,xl=X.shape
  Yp=[]
  sl=len(s)
  for i,x in enumerate(X):
    sx=concatenate([s,x])
    s=forward(w,sx)
    Yp.append(activation(jsm(s)))
  return Yp

@jit
def predict_supervised(w,s,X,Y,pre_thresh,eps):
  Yp=[]
  l=len(s)
  for i,(x,y) in enumerate(zip(X,Y)):
    sx=concatenate([s,x])
    s0=forward(w,sx)
    yp=jsm(s0)
    Yp.append(yp)
    s=s0+(signbit(yp-pre_thresh)^y)*\
         (1+eps)*(pre_thresh-yp)/l

  return array(Yp),s

'''
@jit
def loss(w,s0,X,Y,rw,lr,reg):
  Yp=predict_supervised(w,s0,X,Y)[0]
  w_pos=exp(rw)
  w_neg=1/w_pos
  sm_weights=w_pos+w_neg
  w_pos/=sm_weights
  w_neg/=sm_weights
  diff=jsm((w_pos+(w_neg-w_pos)*Y)*\
           (1-((2*Y-1)*activation(Yp))))
  l2=sum(jsm(a**2) for a in w[0])+\
     sum(jsm(a**2) for a in w[1])
  return lr*diff+reg*l2
'''

@jit
def hinge(w,s0,X,Y,pre_thresh,eps):
  Yp=predict_supervised(w,s0,X,Y,pre_thresh,eps)[0]
  return jsm(maximum((pre_thresh-Yp)*(Y-.5),0))
  #return jsm(log(eps+maximum((thresh-Yp)*(Y-.5),0))-log(eps))
dh=jit(value_and_grad(hinge))

@jit
def hinge_loss(w,s0,X,Y,pre_thresh,eps,reg,lr):
  return reg*l2(w)+lr*hinge(w,s0,X,Y,pre_thresh,eps)

@jit
def update(w,dw):
  return ([a-da for a,da in zip(w[0],dw[0])],
          [b-db for b,db in zip(w[1],dw[1])])
@jit
def update_logarithmic(w,dw,eps):
  return ([a-da/log(1+eps+abs(a)) for a,da in zip(w[0],dw[0])],
          [b-db for b,db in zip(w[1],dw[1])])

def print_weight_met(w,lab,f=lambda a:jsm(a**2)):
  print(lab+'a,'+lab+'b')
  [print(f(a),f(b)) for a,b in zip(*w)]

#dloss=jit(value_and_grad(loss))
dhinge_loss=jit(value_and_grad(hinge_loss))
target_fp=.1
target_fn=.01
cycle_len=128
max_start=n_r-cycle_len
s0=zeros(state_dim)
s=s0
step=0
#bs=128
print_int=100
lr=1e-2
reg=1e-6#1e-3
eps=1e-5
adaptive_thresh_rate=.5*(1-2*(3**-1.5))*min(target_fp,target_fn)
bs=1
n_samps=(bs*cycle_len)
avg_rate=max(.1,(min(target_fp,target_fn)**2)*n_samps)
start=0
YYp=[]
YY=[]
otfw=OTFBinWeights(avg_rate,target_fp,target_fn,
                   adaptive_thresh_rate)
ts=TimeStepper()
l=1.
adj=.9
beta1=.9
beta2=.999
while True:
  ts.get_timestep('start_loop')
  end=start+cycle_len
  x,y=x_r[start:end],y_r[start:end]
  ts.get_timestep('get_x_y')
  l=abs(l)
  l,dw=dhinge_loss(w,s,x,y,otfw.pre_thresh,eps,reg,lr)
  if not isfinite(l):
    l_2,d_l2=dl2(w)
    if not isfinite(l_2):
      reg/=adj
    h,d_h=dh(w,s,x,y,otfw.pre_thresh,eps)
    if not isfinite(h):
      lr/=adj
    #dl2l2=l2(d_l2)
    #div_reg=min(log(max(2,dl2l2)),2)
    #reg/=div_reg
    #dhl2=l2(d_h)
    #div_lr=min(log(max(2,dhl2)),2)
    #lr/=div_lr
    print('Encountered non-finite loss:')
    print('l2,hinge:',l_2,h)
    print('lr/=',adj)
    print('lr<-',lr)
    print('reg/=',adj)
    print('reg<-',reg)
    print('Reverting l2...')
    w=wl
    if not(isfinite(l2(wl))):
      print('Still not finite:')
      print('w<-act(lr*w)/lr')
      print_weight_met(w,'upon nonfinite: w')
      w=([activation(lr*a)/lr for a in w[0]],
         [activation(lr*b)/lr for b in w[1]])
    print('upon nonfinite: s:',*[float(si) for si in s])
    s=sl
    continue
  ts.get_timestep('loss')
  sl=s
  yp_s,s=predict_supervised(w,s,x,y,otfw.pre_thresh,eps)
  yp=yp_s>otfw.pre_thresh
  ts.get_timestep('predict')
  otfw.upd(y,yp)
  otfw.report()
  ts.get_timestep('update_stats')
  wl=w
  #w=update_logarithmic(w,dw,eps=eps)
  #w=update_logarithmic(w,dw)
  w,v,m,wl2,dwl2=upd_adam(w,v,m,dw,beta1,beta2,1.)
  ts.get_timestep('update')
  if not(step%print_int):
    print()
    print(step)
    print('start position:',start)
    print('Last loss:',l)
    print('lr,reg,eps:',
          ','.join((str(lr),str(reg),str(eps))))
    print('w2,dw2',wl2,',',dwl2)
    line=read_input_if_ready()
    if line:
      print('=============================')
      if 't' in line:
        ts.report(p=True)
      if 'h' in line:
        print('Hidden state:',*[float(si) for si in s])
      if 's' in line:
        print('squares')
        print('w')
        print_weight_met(w,'w')
        print('dw')
        print_weight_met(dw,'dw')
      if 'd' in line:
        print('disk usage')
        print('w')
        print_weight_met(w,'w',f=lambda a:size(a)/1024)
      if 'p' in line:
        n_to_predict=line.split('p')[0]
        if n_to_predict:
          try:
            n_to_predict=int(n_to_predict)
            X,Y=x_e[:n_to_predict],y_e[:n_to_predict]
          except:
            if n_to_predict:
              print('Unable to convert',n_to_predict,'to int, ',
                    end='')
              n_to_predict=1000
          X,Y=x_e[:n_to_predict],y_e[:n_to_predict]
          print('Making predictions for  first',
                n_to_predict,'rows of test set')
        else:
          X,Y=x_e,y_e
        n_runs=n_to_predict//cycle_len
        tp_t=tn_t=fp_t=0.
        for x,y in zip(array_split(X,n_runs),array_split(Y,n_runs)):
          yp_s,s_f=predict_supervised(w,s0,x,y,thresh,eps)
          yp=yp_s>otfw.pre_thresh
          tp_t+=jsm(Yp&Y)/nt
          tn_t+=jsm(~(Yp|Y))/nt
          fp_t+=jsm(Yp&~Y)/nt
        tp_t/=n_to_predict
        tn_t/=n_to_predict
        fp_t/=n_to_predict
        fn_t=1-tp_t-tn_t-fp_t
        print('tp:',tp_t,'tn:',tn_t,'fp:',fp_t,'fn:',fn_t)
      print('=============================')
    print()
  ts.get_timestep('report')
  step+=1
  start=end
  if end>n_r:
    k,_=split(k)
    start=randint(k,(),0,max_start)
    s=s0
  ts.get_timestep('end_loop')
