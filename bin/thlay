#!/usr/bin/env python
from csv import writer
from pandas import read_csv
from types import SimpleNamespace
from pickle import load,dump
from time import perf_counter
from matplotlib.pyplot import title,imshow,legend,show,scatter,xlabel,ylabel,\
                              gca,plot,savefig,close
from matplotlib import colormaps
from matplotlib.patches import Patch
from matplotlib.cm import jet
from numpy import geomspace,prod
from jax.numpy import array,array_split,dot,vectorize,add,linspace,convolve,\
                      log,exp,eye,flip,maximum,minimum,unique,concat,ones,\
                      sin,zeros,sum as nsm,max as nmx
from jax.numpy.linalg import svd
from jax.random import normal,key,uniform,split,choice
from jax.nn import tanh,softmax
from jax import grad
from jax.lax import scan
from sklearn.utils.extmath import cartesian
from sys import path,stdin
from os import mkdir
from select import select
from argparse import ArgumentParser
ap=ArgumentParser()
ap.add_argument('mode',default='all',
                choices=['single','all','adaptive_lr','imbalances','unsw','gmm'])

ap.add_argument('-n_gaussians',default=4,type=int)
ap.add_argument('-gmm_spread',default=.05,type=float)
ap.add_argument('-gmm_scatter_samples',default=10000,type=int)

ap.add_argument('-act',choices=['relu','tanh','softmax'],default='tanh')
ap.add_argument('--seed',default=20255202,type=int)
ap.add_argument('-n_splits_img',default=100,type=int)

ap.add_argument('-imbalances',default=array([.01,.02,.1]),nargs='+')
                #,type=lambda x:array(x),

ap.add_argument('-in_dim',default=2,type=int)

ap.add_argument('-unsw_cat_thresh',default=.1,type=int)

ap.add_argument('-lr_resolution',default=16,type=int)
ap.add_argument('-all_resolution',default=5,type=int)

ap.add_argument('-max_history_len',default=16384,type=int)

ap.add_argument('-weight_normalisation',default=0.,type=float)#.0001
ap.add_argument('-orthonormalise',action='store_true')

ap.add_argument('-reporting_interval',default=10,type=int)
ap.add_argument('-saving_interval',default=100,type=int)

ap.add_argument('-lr_init_min',default=1e-4,type=float)
ap.add_argument('-lr_init_max',default=1e-2,type=float)
ap.add_argument('-lr_min',default=1e-5,type=float)
ap.add_argument('-lr_max',default=1e-1,type=float)

ap.add_argument('-lr',default=1e-4,type=float)
ap.add_argument('-lr_update_interval',default=1000,type=int)
ap.add_argument('-lr_update_memory',default=1000,type=int)

ap.add_argument('-gamma1',default=.1,type=float) #1- beta1 in adam
ap.add_argument('-gamma2',default=.001,type=float)

ap.add_argument('-avg_rate',default=.1,type=float)#.01,type=float)

ap.add_argument('-unsw_test',default='~/data/UNSW_NB15_testing-set.csv')
ap.add_argument('-unsw_train',default='~/data/UNSW_NB15_training-set.csv')

#ap.add_argument('-model_inner_dims',default=[64,16,4],type=int,nargs='+')
#ap.add_argument('-model_inner_dims',default=[32,16,8],type=int,nargs='+')
ap.add_argument('-model_inner_dims',default=[128,16,8],type=int,nargs='+')

ap.add_argument('-bs',default=1,type=int)

ap.add_argument('-res',default=1000,type=int)

ap.add_argument('-outf',default='thlay')

ap.add_argument('-new',action='store_true')

ap.add_argument('-model_sigma_w',default=1.,type=float)#.3
ap.add_argument('-model_sigma_b',default=1.,type=float)#0.
ap.add_argument('-no_sqrt_normalise_w',action='store_true')
ap.add_argument('-no_glorot_uniform',action='store_true')
ap.add_argument('-model_resid',default=False,type=bool)

ap.add_argument('-p',default=.1,type=float)
ap.add_argument('-target_fp',default=.01,type=float)
ap.add_argument('-target_fn',default=.01,type=float)

#Silly
ap.add_argument('-lr_phase',default=0.,type=float)
ap.add_argument('-lr_momentum',default=0.05,type=float)
ap.add_argument('-lr_amplitude',default=0.,type=float)
ap.add_argument('-x_max',default=10.,type=float)

args=ap.parse_args()
args.uniform_b_0=False#args.mode in ['gmm','single','all']
args.step=0

f_to_str= lambda x,p=True:f'{x:.5g}'.ljust(10) if p else f'{x:.5g}'

exp_to_str=lambda e:'exp_p'+f_to_str(e.p,p=False)+'fpt'+f_to_str(e.target_fp,p=False)+\
                    'fnt'+f_to_str(e.target_fn,p=False)+'lr'+f_to_str(e.lr,p=False)

fpfnp_lab=lambda e:'FP_t,FN_t,p='+f_to_str(e.target_fp,p=False)+','+\
                   f_to_str(e.target_fn,p=False)+','+f_to_str(e.p,p=False)

leg=lambda t=None,h=None,l='upper right':legend(framealpha=0.2,fontsize='x-small',
                                         loc=l,handles=h,title=t)


args.out_dir=args.outf+'_report'

if args.mode in ['single','imbalances','unsw','gmm']:
  lrs=array([args.lr])
elif args.mode=='adaptive_lr':
  lrs=geomspace(args.lr_init_min,args.lr_init_max,num=args.lr_resolution)
else:
  lrs=geomspace(args.lr_init_min,args.lr_init_max,num=args.all_resolution)


def relu(x):return minimum(1,maximum(-1,x))

def f_unbatched(w,x,act=tanh):
  i=0
  while ('b',i) in w:
    x=act(x.dot(w[('w',i)])+w[('b',i)])
    i+=1
  if act==softmax:
    x-=.5
  return x
f=vectorize(f_unbatched,excluded=[0],signature='(m)->(n)')

def loss(w,x,y,U,V,act=tanh,normalisation=False):
  y_smooth=f(w,x,act=act)
  #cts_fp=nsm(maximum(V-U,y_smooth)[~y])
  #cts_fn=nsm(maximum(U-V,-y_smooth)[y])
  #cts_fp=nsm(maximum(0,y_smooth)[~y])
  #cts_fn=nsm(maximum(0,-y_smooth)[y])
  #cts_fp=nsm((~y)*(y_smooth+.5))
  #cts_fn=nsm(y*(.5-y_smooth))
  cts_fp=nsm((y_smooth+1.)[~y])
  cts_fn=nsm((1.-y_smooth)[y])
  if normalisation:
    l2=sum([nsm(w[('w',i)]**2)*nf for\
            i,nf in enumerate(normalisation)])
  return U*cts_fp+V*cts_fn+l2

dL=grad(loss)

global_key=key(args.seed)
def emit_key():
  global global_key
  global_key,child_key=split(global_key)
  return child_key

def init_layers(sigma_w,sigma_b,layer_dimensions,key,no_sqrt_normalise=False,
                resid=False,glorot_uniform=False,orthonormalise=False):
  wb=[]
  n_steps=len(layer_dimensions)-1
  w_k=split(emit_key(),num=n_steps)
  b_k=split(emit_key(),num=n_steps)
  ret=dict()
  for i,(k,l,d_i,d_o) in enumerate(zip(w_k,b_k,layer_dimensions,layer_dimensions[1:])):
    if glorot_uniform:
      ret[('w',i)]=2*(6/(d_i+d_o))**.5*(uniform(shape=(d_i,d_o),key=k)-.5)
      ret[('b',i)]=zeros(shape=d_o)
    else:
      ret[('w',i)]=normal(shape=(d_i,d_o),key=k)
      ret[('b',i)]=normal(shape=d_o,key=l)
    if resid:
      ret[('w',i)]+=eye(*ret[('w',i)].shape)
  if glorot_uniform:
    return ret
  if orthonormalise:
    for i,(d_i,d_o) in enumerate(zip(layer_dimensions,layer_dimensions[1:])):
      if d_i>d_o:
        ret[('w',i)]=svd(ret[('w',i)],full_matrices=False)[0]
      else:
        ret[('w',i)]=svd(ret[('w',i)],full_matrices=False)[2]
  for i in range(len(layer_dimensions)-1):
    ret[('w',i)]*=sigma_w
    ret[('b',i)]*=sigma_b
  if no_sqrt_normalise:
    return ret
  for i,d_i in enumerate(layer_dimensions[1:]):
    ret[('w',i)]/=d_i**.5
  return ret

def sample_x(bs,key):
  return 2*args.x_max*uniform(shape=(bs,2),key=key)-args.x_max

def size_rescale(l):
  return 25*(1+log(args.lr_max)-log(l))

def colour_rescale(fpfn):
  l=log(array(fpfn))-log(args.fpfn_min)
  l/=log(args.fpfn_max)-log(args.fpfn_min)
  return jet(l)

def mk_experiment(w_model_init,p,thresh,target_fp,target_fn,lr,
                  mem=args.lr_update_memory):
  e=SimpleNamespace()
  e.FPs=[0]*mem
  e.FNs=[0]*mem
  e.w_model=args.w_model_init.copy()

  e.lr=float(lr)
  e.size=size_rescale(lr) #for plotting
  e.p=float(p) #"imbalance"
  e.target_fp=target_fp
  e.target_fn=target_fn
  if args.mode=='all':
    e.colour=colour_rescale(target_fp/target_fn)
  e.fp=target_fp
  e.fn=target_fn#.25 #softer start if a priori assume doing well

  e.U=e.V=1
  e.thresh=thresh
  e.history=SimpleNamespace(FP=[],FN=[],lr=[],cost=[],dw=[],resolution=1,l=0)
  return e

try:
  mkdir(args.out_dir)
  args.new=True
except FileExistsError:
  if args.new:
    print('Already seems to be something there... [O]verwrite, [L]oad or [A]bort?')
    ln=stdin.readline()[0].lower()
    if ln[0]=='l':
      args.new=False
    elif ln[0]=='o':
      print('Overwriting any existing ensembles...')
    else:
      print('Abort!')
      exit()
  else:
    print('Directory already exists!')
    exit(1)

if not args.new:
  try:
    with open(args.out_dir+'/ensemble.pkl','rb') as fd:
      print('Opening experiment ensemble',args.outf,'...')
      od=args.out_dir #Correct the actual directory if opened somewhere else
      args,experiments,global_key=load(fd)
      args.out_dir=od
      args.new=False
      global_key=args.global_key
      print('Restored',args.outf+'.pkl','from disk')
  except FileNotFoundError:
    print('No pkl in directory...')
    args.new=True

if args.new:
  print('Generating new ensemble...')
  
  args.global_key=global_key
  args.time_avgs=dict()
  args.target_shape=[2]+[16]*8+[1]

  if args.mode=='unsw':
    df_train=read_csv(args.unsw_train)
    df_test=read_csv(args.unsw_test)
    args.x_test=array(df_test[df_test.columns[(df_test.dtypes==int)|\
                                              (df_test.dtypes==float)]]).T[1:].T
    args.x_train=array(df_test[df_train.columns[(df_train.dtypes==int)|\
                                                (df_train.dtypes==float)]]).T[1:].T
    args.y_train=df_train['attack_cat']
    args.y_test=df_test['attack_cat']
    args.in_dim=len(args.x_train[0])

  args.target_sigma_w=.75
  args.target_sigma_b=2.
  
  args.w_target=init_layers(args.target_sigma_w,args.target_sigma_b,
                            args.target_shape,emit_key())
  args.model_shape=[args.in_dim]+args.model_inner_dims+[1]

  args.w_model_init=init_layers(args.model_sigma_w,args.model_sigma_b,args.model_shape,
                                resid=args.model_resid,
                                glorot_uniform=not args.no_glorot_uniform,key=emit_key(),
                                no_sqrt_normalise=args.no_sqrt_normalise_w,
                                orthonormalise=args.orthonormalise)
  args.normalisation_factors=[args.weight_normalisation/\
                              (nsm(args.w_model_init[('w',i)]**2)*\
                               args.w_model_init[('w',i)].size) for\
                              i in range(len(args.model_shape)-1)]

  if args.uniform_b_0: #uniform biases
    args.w_model_init[('b',0)]=uniform(emit_key(),shape=args.model_shape[1])*\
                               2*args.x_max-args.x_max
  
  if args.mode in ['imbalances','gmm']:
    args.target_fps=[.15,.1,.05]
    args.target_fns=[.1]
  elif args.mode=='unsw':
    args.imbalances=(args.y_train.value_counts()+args.y_test.value_counts())/\
                    (len(df_train)+len(df_test))
    args.cats={float(p):s for p,s in\
               zip(args.imbalances,args.y_train.value_counts().index)}
    args.imbalances=args.imbalances[args.imbalances>args.unsw_cat_thresh]
    args.target_fps=[.15,.1,.05]
    args.target_fns=[.1]
  elif args.mode=='single':
    args.imbalances=[args.p]
    args.target_fps=[args.target_fp]
    args.target_fns=[args.target_fn]
  else:

    args.target_fp_min,args.target_fp_max=.001,.01
    args.target_fn_min,args.target_fn_max=.001,.01
    args.target_fps=geomspace(args.target_fp_min,args.target_fp_max,
                            num=args.all_resolution)
    args.target_fns=geomspace(args.target_fn_min,args.target_fn_max,
                            num=args.all_resolution)
  
  if args.mode in ['unsw','gmm']:
    args.thresholds={float(p):0. for p in args.imbalances}
  else:
    print('Finding thresholds...')
    args.threshold_accuracy_tolerance=.01 #Within 1% of right value with high probability
    
    
    thresholding_sample_size=int(1/(args.threshold_accuracy_tolerance**2*\
                                    args.imbalance_min))
    x_thresholding=sample_x(thresholding_sample_size,emit_key())
    
    y_t_cts=f(args.w_target,x_thresholding).flatten()
    y_t_cts_sorted=y_t_cts.sort()
    args.thresholds={float(p):y_t_cts_sorted[-int(p*len(y_t_cts_sorted))]\
                    for p in args.imbalances}
    
    print('Imbalances and thresholds')
    for i,t in args.thresholds.items(): print(i,t)
  
  args.clock_avg_rate=.1
  args.loop_master_key=emit_key()
  args.step=0


  if args.mode=='all':
    args.fpfns=[a/b for a,b in zip(args.target_fps,args.target_fns)]
    args.fpfn_max,args.fpfn_min=args.fpfns[-1],args.fpfns[0]
    args.fpfn_colours=zip([colour_rescale(fpfn) for fpfn in args.fpfns],args.fpfns)
    colour_handles=[Patch(color=c,label=str(s)) for c,s in args.fpfn_colours]
  
    args.targets=list(zip(args.target_fps,args.target_fns))
    experiments=[mk_experiment(args.w_model_init,p,args.thresholds[p],
                               target_fp,target_fn,lr)\
                 for p in args.imbalances\
                 for (target_fp,target_fn) in args.targets\
                 for lr in lrs]

  elif args.mode=='single':
    experiments=[mk_experiment(args.w_model_init,.1,args.thresholds[.1],.01,.01,args.lr)]
  elif args.mode=='adaptive_lr':
    experiments=[mk_experiment(args.w_model_init,.1,args.thresholds[.1],.01,.01,lr) for\
                 lr in lrs]
  elif args.mode in ['unsw','gmm']:
    experiments=[mk_experiment(args.w_model_init,float(p),0.,
                               float(p*target_fp),float(p*target_fn),args.lr)\
                 for p in args.imbalances\
                 for target_fp in args.target_fps\
                 for target_fn in args.target_fns]
  elif args.mode in ['imbalances']:
    experiments=[mk_experiment(args.w_model_init,float(p),
                               float(args.thresholds[float(p)]),
                               float(p*target_fp),float(p*target_fn),args.lr)\
                 for p in args.imbalances\
                 for target_fp in args.target_fps\
                 for target_fn in args.target_fns]

  if args.mode=='gmm':
    args.means=2*args.x_max*uniform(emit_key(),(2*args.n_gaussians,args.in_dim))-\
               args.x_max
    args.variances=2*args.x_max*uniform(emit_key(),2*args.n_gaussians)*\
                   args.gmm_spread #hmm


#Would like to pickle but unable to do so to lambdas
act={'tanh':tanh,'relu':relu,'softmax':softmax}[args.act]
probs=lambda p:array(([(1.-p)/args.n_gaussians]*args.n_gaussians)+\
                     ([p/args.n_gaussians]*args.n_gaussians))
def get_gmm_xy(p,bs):
  mix=choice(emit_key(),2*args.n_gaussians,shape=(bs,),p=probs(p))
  y=mix>=args.n_gaussians
  z=normal(emit_key(),shape=(bs,args.in_dim))
  x=z*args.variances[mix,None]+\
    args.means[mix]
  return x,y

def get_timestep(label):
  global tl
  t=perf_counter()
  try: args.time_avgs[label]+=(1+args.clock_avg_rate)*args.clock_avg_rate*float(t-tl)
  except: args.time_avgs[label]=(1+args.clock_avg_rate)*float(t-tl)
  args.time_avgs[label]*=(1-args.clock_avg_rate)
  tl=t

while True:
  args.step+=1
  if not args.step%10:print(args.step)
  if args.mode=='unsw':
    batch_indices=choice(emit_key(),len(args.y_train),shape=(args.bs,))
    x=args.x_train[batch_indices]
    y_ts={float(p):array(args.y_train[batch_indices]==args.cats[p]) for\
          p in args.imbalances}

  elif args.mode=='gmm':
    xy=dict()
    for p in args.imbalances:
      xy[float(p)]=get_gmm_xy(p,args.bs)
  else:
    x=sample_x(args.bs,emit_key())
    y_t_cts=f(args.w_target,x).flatten()
    y_ts={float(p):y_t_cts>thresh for p,thresh in args.thresholds.items()}

  args.lr_phase+=args.lr_momentum
  for e in experiments:
    if args.mode=='gmm':
      x,e.y_t=xy[float(e.p)]
    else:
      e.y_t=y_ts[float(e.p)]

    if args.mode not in ['adaptive_lr','all']:
      e.lr=args.lr*exp(args.lr_amplitude*sin(args.lr_phase))
    e.bs=len(e.y_t)
    tl=perf_counter()
    y_p_cts=f(e.w_model,x,act=act).flatten()
    y_p=y_p_cts>0
    get_timestep('threshold')

    FP=int(nsm(y_p&(~e.y_t))) #Stop jax weirdness after ADC
    FN=int(nsm(e.y_t&(~y_p)))
    e.FPs[args.step%args.lr_update_memory]=FP
    e.FNs[args.step%args.lr_update_memory]=FN
    window_div=min(args.step,args.lr_update_memory)
    e.fp_window=sum(e.FPs)/window_div
    e.fn_window=sum(e.FNs)/window_div
    e.cost_window=(e.fp_window/e.target_fp+e.fn_window/e.target_fn)/e.bs
    if not args.step%e.history.resolution:
      e.history.FP.append(FP)
      e.history.FN.append(FN)
      e.history.lr.append(e.lr)
      e.history.cost.append(e.cost_window)
      e.history.l+=1
      if e.history.l>args.max_history_len:
        e.history.resolution*=2
        e.history.FP=[fp for i,fp in enumerate(e.history.FP) if i%2]
        e.history.FN=[fn for i,fn in enumerate(e.history.FN) if i%2]
        e.history.lr=[lr for i,lr in enumerate(e.history.lr) if i%2]
        e.history.cost=[c for i,c in enumerate(e.history.cost) if i%2]
        e.history.dw=[w for i,w in enumerate(e.history.dw) if i%2]
        e.history.l//=2


    e.fp_amnt=args.avg_rate*min(1,e.bs*e.fp)
    e.fn_amnt=args.avg_rate*min(1,e.bs*e.fn)
    #e.fp_amnt=1.
    #e.fn_amnt=1.
    e.fp*=(1-e.fp_amnt)
    e.fp+=e.fp_amnt*FP/e.bs
    e.fn*=(1-e.fn_amnt)
    e.fn+=e.fn_amnt*FN/e.bs

    #e.p_empirical*=(1-min(e.fp_amnt,e.fn_amnt))
    #e.p_empirical+=(1-min(e.fp_amnt,e.fn_amnt))*nsm(e.y_t)/e.bs
    #U,V=log(1+fp/target_fp),log(1+fn/target_fn)
    #U=u/(u+v)
    #V=v/(u+v)
    #U,V=softmax(array([gamma1*fp/target_fp,gamma1*fn/target_fn]))
    #U,V=softmax(array([fp/target_fp,fn/target_fn]))

    e.U,e.V=e.fp/e.target_fp,e.fn/e.target_fn
    e.V/=e.p #scale dfn with the imbalance
    #nUV=(e.U**2+e.V**2)**.5
    nUV=e.U+e.V
    if nUV>0:
      e.U/=nUV
      e.V/=nUV
    get_timestep('U,V')

    upd=dL(e.w_model,x,e.y_t,e.U,e.V,act=act,normalisation=args.normalisation_factors)
    get_timestep('dL')

    e.dw_l2=e.w_l2=0
    try:
      e.adam_M*=(1-args.gamma2)
      for k in upd:#Should apply to all bits simultaneously?
        e.adam_V[k]*=(1-args.gamma1)
        e.adam_V[k]+=args.gamma1*upd[k]
        e.adam_M+=args.gamma2*nsm(upd[k]**2)
    except AttributeError:
      print('Initialising adam weights...')
      e.adam_V=upd
      e.adam_M=sum([nsm(upd[k]**2) for k in upd])
    get_timestep('adam')
    for k in e.adam_V:
      delta=e.lr*e.adam_V[k]/(e.adam_M**.5+1e-8)
      e.w_model[k]-=delta
      ch_l2=nsm(delta**2)
      e.dw_l2+=ch_l2
      weight_l2=nsm(e.w_model[k]**2)
      e.w_l2+=weight_l2
    e.history.dw.append(e.dw_l2)
    get_timestep('updating')

    
  if not args.step%args.lr_update_interval and args.mode=='adaptive_lr':
    experiments=sorted(experiments,key=lambda x:x.cost_window)
    goodnesses=array([1/(1e-8+e.cost_window) for e in experiments])
    e_lr=v_lr=0.
    for e,g in zip(experiments,goodnesses):
      print('lr,un-normalised goodnesses=',e.lr,g)
      le_lr+=log(e.lr)/log(2)
      lv_lr+=(log(e.lr)/log(2))**2
    le_lr/=len(experiments)
    lv_lr/=len(experiments)
    lv_lr-=le_le**2
    print('E(log(lr)),V(log(lr))=',le_lr,lv_lr)
    goodnesses/=nsm(goodnesses)
    experiment_indices=array(range(len(experiments)))
    e=experiments[-1]
    parent=experiments[int(choice(emit_key(),experiment_indices,p=goodnesses))]
    e.lr=parent.lr
    w=lambda x,y,z:(x*z,y/z)
    if parent.lr>args.lr_max: rule=lambda x,y:(x,y*exp(-abs(normal(emit_key()))))
    elif parent.lr<args.lr_min: rule=lambda x,y:(x,y*exp(abs(normal(emit_key()))))
    else: rule=lambda x,y:w(x,y,exp(normal(emit_key())))
    parent.lr,e.lr=rule(parent.lr,e.lr)

    if uniform(emit_key())<e.cost_window/(1e-8+parent.cost_window)-1:
      print('Weight copying')
      e.w_model=parent.w_model.copy()
      e.adam_M=parent.adam_M.copy()
      e.adam_V=parent.adam_V.copy()
      e.fp=float(parent.fp)
      e.fn=float(parent.fn)
    lrs=array([e.lr for e in experiments])

  fd_tex=False
  line=''
  args.reporting_interval=10
  if not args.step%args.reporting_interval:

    print('|'.join([t.ljust(10) for t in ['p','target_fp','target_fn',
                                          'lr','fp','fn','w','dw','U','V']]))
    for e in experiments:
      print('|'.join([f_to_str(t) for t in [e.p,e.target_fp,e.target_fn,e.lr,
                                            e.fp,e.fn,e.w_l2,e.dw_l2,e.U,e.V]]))
    for e in experiments:
      print('Recent outcomes:')
      print('FP by batch',e.FPs[args.step%args.lr_update_memory-5:\
                                args.step%args.lr_update_memory])
      print('FN by batch',e.FNs[args.step%args.lr_update_memory-5:\
                                args.step%args.lr_update_memory])
    if stdin in select([stdin],[],[],0)[0]:
      line+=stdin.readline().lower()
      if ':' in line:
        line=line.split(':')

        if line[0]=='f':
          ty=float
        elif line[0]=='i':
          ty=int
        vars(args)[line[1]]=ty(line[2])
        print('args.'+line[1]+'<-'+str(ty(line[2])))
        line=''
      elif '?' in line:
        try:
          print(vars(args)[line.split('?')[0]])
        except KeyError:
          print('"',line.split('?')[0],'" not in args')
      elif '*' in line:
        print('args variables:')
        [print(v) for v in vars(args).keys()]
  if line:
    if 'x' in line:
      print('Bye!')
      exit()
    fp_perf=[]
    fn_perf=[]
    colours=[]
    sizes=[]
    if 'r' in line:
      line+='clis'
      args.report_dir=args.outf+'_report'
      fd_tex=open(args.outf+'_report/report.tex','w')
      print('\\documentclass[landscape]{article}\n'
            '\\usepackage[margin=0.7in]{geometry}\n'
            '\\usepackage[utf8]{inputenc}\n'
            '\\usepackage{graphicx}\n'
            '\\usepackage{float}\n'
            '\\usepackage{caption}\n'
            '\\usepackage{subcaption}\n'
            '\\usepackage{amsmath,amssymb,amsfonts,amsthm}\n'
            '\n'
            '\\title{Experiment ensemble report: '+args.mode+'}\n'
            '\\author{George Lee}\n'
            '\n'
            '\\begin{document}\n'
            '\\maketitle\n'
            'Report for ensemble labelled '+args.outf.replace('_','\\_')+'\n'
            '\\subsection{Performance after '+str(args.step)+' steps}',file=fd_tex)
      
      with open(args.out_dir+'/performance.csv','w') as fd_csv:
        w=writer(fd_csv)
        n_fps=len(args.target_fps)
        row=['imbalance','target_fps']+['']*(n_fps-1)+['target_fn','fps']+\
            ['']*(n_fps-1)+['fns']+['']*(n_fps-1)
        if args.mode=='unsw':
          row=['attack_cat']+row
        w.writerow(row)
        if fd_tex:
          conf_fill='r'*n_fps
          ct='l' if args.mode=='unsw' else ''
          print('\\begin{tabular}{l'+ct+'|'+conf_fill+'|r|'+conf_fill+'|'+conf_fill+'}',
                file=fd_tex)
          print(' & '.join(row).replace('_',' ')+'\\\\',file=fd_tex)
          print('\\hline',file=fd_tex)
        n_imbalances=len(args.imbalances)
        for p in args.imbalances:
          tgt_fps=[]
          recent_fps=[]
          recent_fns=[]
          for e in [e for e in experiments if e.p==p]:
            tgt_fps.append(f_to_str(e.target_fp))
            fp_hist=e.history.FP[-int(10/e.p**2):]
            fn_hist=e.history.FN[-int(10/e.p**2):]
            recent_fps.append(f_to_str(sum(fp_hist)/(e.bs*len(fp_hist))))
            recent_fns.append(f_to_str(sum(fn_hist)/(e.bs*len(fn_hist))))
          row=[f_to_str(p)]+tgt_fps+[f_to_str(p/10)]+recent_fps+recent_fns
          if args.mode=='unsw':
            row=[args.cats[p]]+row
          w.writerow(row)
          if fd_tex:
            print('&'.join(row)+'\\\\',file=fd_tex)
    if fd_tex:
      print('\\end{tabular}\n'
            '\\subsection{Timing analysis of update step}\n'
            'Distinct steps in the algorithm taking on average:\\\\\n'
            '\\begin{tabular}{r|r}\n'
            'step&$\\log(\\overline{\\texttt{T}_\\texttt{step}})$\\\\\n',file=fd_tex)

    print('Timing:')
    for k,v in args.time_avgs.items():
      print(k,log(v)/log(2))
      if fd_tex: print('\\texttt{'+k+'}&'+f_to_str(log(v)/log(2))+'\\\\\n',file=fd_tex)
    if fd_tex: print('\\end{tabular}',file=fd_tex)

    if args.in_dim==2 and 'c' in line:
      if fd_tex:
        print('\\subsection{2d visualisation of classifications}',file=fd_tex)
        print('Here a 2d region is learned.\\\\',file=fd_tex)
        print('\n\\begin{figure}[H]',file=fd_tex)
        print('\\centering',file=fd_tex)
      for e in experiments:
        if args.mode=='gmm':
          x_t,y_t=get_gmm_xy(e.p,args.gmm_scatter_samples)
          col_mat=[[1.,1,1],[0,0,0]]#fp,fn,tp,tn
          labs=['Predict +','Predict -']
          x_0_max=nmx(x_t[:,0])
          x_0_min=-nmx(-x_t[:,0])
          x_1_max=nmx(x_t[:,1])
          x_1_min=-nmx(-x_t[:,1])
        else:
          x_0_max=x_1_max=args.x_max
          x_0_min=x_1_min=-args.x_max
        x=cartesian([linspace(x_0_min,x_0_max,num=args.res),
                     linspace(x_1_min,x_1_max,num=args.res)])
        x_split=array_split(x,args.n_splits_img)
        #y_p=array([(f(e.w_model,xax,act=act)>0).flatten() for xax in x])
        y_p=concat([(f(e.w_model,_x,act=act)>0).flatten() for _x in x_split])
        y_p=flip(y_p.reshape(args.res,args.res),axis=1) #?!?!?!

        if args.mode=='gmm':
          regions=array([y_p,~y_p]).T
        else:
          y_t=concat([f(args.w_target,_x)>e.thresh for _x in x_split])\
              .reshape(args.res,args.res)
          fp_img=(y_p&~y_t)
          fn_img=(~y_p&y_t)
          tp_img=(y_p&y_t)
          tn_img=(~y_p&~y_t)
          regions=array([fp_img,fn_img,tp_img,tn_img]).T
          col_mat=[[1.,0,0],[0,1,0],[1,1,1],[0,0,0]]#fp,fn,tp,tn
          labs=['FP','FN','TP','TN']
        cols=regions.dot(array(col_mat))
        imshow(cols,extent=[x_0_min,x_0_max,x_1_min,x_1_max])
        handles=[Patch(color=c,label=s) for c,s in zip(col_mat,labs)]
        if args.mode=='gmm':
          x_0,x_1=tuple(x_t.T)
          y_p_s=f(e.w_model,x_t,act=act).flatten()>0
          scatter(x_0[y_t&y_p_s],x_1[y_t&y_p_s],c='darkgreen',s=1,label='TP')
          scatter(x_0[y_t&~y_p_s],x_1[y_t&~y_p_s],c='palegreen',s=1,label='FP')
          scatter(x_0[~y_t&~y_p_s],x_1[~y_t&~y_p_s],c='cyan',s=1,label='TN')
          scatter(x_0[~y_t&y_p_s],x_1[~y_t&y_p_s],c='blue',s=1,label='FN')
          handles+=[Patch(color=c,label=s) for c,s in\
                    zip(['blue','palegreen','darkgreen','cyan'],['FP','FN','TP','TN'])]
        leg(h=handles,l='lower left')
        title('p='+f_to_str(e.p,p=False)+',target_fp='+f_to_str(e.target_fp,p=False)+\
              ',target_fn='+f_to_str(e.target_fn,p=False)+',lr='+f_to_str(e.lr,p=False))
        if fd_tex:
          img_name=exp_to_str(e)+'.png'
          savefig(args.report_dir+'/'+img_name,dpi=500)
          print('\\begin{subfigure}{.33\\textwidth}',file=fd_tex)
          print('\\centering',file=fd_tex)
          print('\\includegraphics[width=.9\\linewidth,scale=1]{'+img_name+'}',
                file=fd_tex)
          print('\\end{subfigure}%',file=fd_tex)
          print('\\hfill',file=fd_tex)
          close()
        else:
          show()

      if fd_tex:
        print('\\end{figure}',file=fd_tex)
      fp_perf.append(e.fp/e.target_fp)
      fn_perf.append(e.fn/e.target_fn)
      if args.mode=='all':
        colours.append(e.colour)
      else:
        colours=None

      sizes.append(e.size)
    if 'i' in line:
      model_desc='Model shape:\n'+('->'.join([str(l) for l in args.model_shape]))+'\n'
    
      args.no_glorot_uniform=False
      if args.no_glorot_uniform:
        model_desc+='\n'.join(['- matrix weight variance:'+\
                               f_to_str(args.model_sigma_w,p=False),
                               '- bias variance:'+f_to_str(args.model_sigma_b,p=False),
                               '- residual initialisation:'+\
                               f_to_str(args.model_resid,p=False),
                               'sqrt variance correction:'+\
                               str(not args.no_sqrt_normalise_w)])
      else:
        model_desc+='\n- Glorot uniform initialisation'
      model_desc+='\n- batch size:'+str(args.bs)
      if args.mode in ['single','gmm']:
        model_desc+='\n- learning rate:'+str(args.lr)
      print(model_desc)
      if fd_tex:
        print('\\subsection{Model parameters}',file=fd_tex)
        print('Here the batch size was set to '+str(args.bs)+'.\\\\',file=fd_tex)
        print('\\texttt{'+(model_desc.replace('\n','}\\\\\n\\texttt{'))+'}\\\\',
              file=fd_tex)
    if 's' in line and args.mode=='all':
      sc=scatter(fp_perf,fn_perf,c=colours,s=sizes)
      lr_sizes=size_rescale(lrs)
      if args.mode=='all':
        cl=leg(h=colour_handles,t='target_fp/target_fn')
      #h=sc.legend_elements(prop="sizes",num=lr_sizes, alpha=0.6)[0]
      #legend(handles=h,labels=[str(r) for r in lrs],loc='lower right',title='lr')
      if args.mode=='all': gca().add_artist(cl)
      xlabel('fp/target_fp')
      ylabel('fn/target_fn')
      if fd_tex:
        savefig(args.report_dir+'/scatter.png',dpi=500)
        close()
        print('\\subsection{Comparing performance}',file=fd_tex)
        print('\n\\begin{figure}[H]',file=fd_tex)
        print('\\centering',file=fd_tex)
        print('\\includegraphics[width=.9\\textwidth]{scatter.png}',file=fd_tex)
        print('\\end{figure}',file=fd_tex)
      else:
        show()
    if 'l' in line:
      if fd_tex:
        print('\\subsection{Historical statistics}',file=fd_tex)
      get_cost=lambda e:e.history.cost
      get_lr=lambda e:e.history.lr
      get_dw=lambda e:e.history.dw
      for get_var,yl,desc in zip([get_cost,get_lr,get_dw],
                                    ['log(1e-8+fp/target_fp+fn/target_fn)','log(lr)',
                                     'log(dw)']
                                 ,['Loss','Learning_rate','Change_in_weights']):
        for e in experiments:
          arr=get_var(e)
          if args.mode=='unsw':
            lab=args.cats[e.p]
          else:
            lab=fpfnp_lab(e)
          plot([log(a)/log(2) for a in arr],label=lab)
        xlabel('Step number *'+str(e.history.resolution))
        ylabel(yl)
        title(desc.replace('_',' '))
        leg()
        if fd_tex:
          savefig(args.report_dir+'/'+desc+'.png',dpi=500)
          close()
          print('\n\\begin{figure}[H]',file=fd_tex)
          print('\\centering',file=fd_tex)
          print('\\includegraphics[width=.9\\textwidth]{'+desc+'.png}',file=fd_tex)
          print('\\end{figure}',file=fd_tex)
        else:
          show()
      for e in experiments:
        conv_len=min(int(args.step**.5),int(1/p))
        ker=ones(conv_len)/conv_len
        smoothed_fp=convolve(array(e.history.FP,dtype=float),ker,'valid')
        smoothed_fn=convolve(array(e.history.FN,dtype=float),ker,'valid')
        plot(smoothed_fp,smoothed_fn,label=fpfnp_lab(e))
        title('FP versus FN rate')
      leg()
      if fd_tex:
        savefig(args.report_dir+'/phase.png',dpi=500)
        close()
        print('\n\\begin{figure}[H]',file=fd_tex)
        print('\\centering',file=fd_tex)
        print('\\includegraphics[width=.9\\textwidth]{phase.png}',file=fd_tex)
        print('\\end{figure}',file=fd_tex)
      else:
        show()

  if fd_tex:
    print('\\end{document}',file=fd_tex,flush=True)
    fd_tex.close()

  fd_tex=False
  if not args.step%args.saving_interval:
    with open(args.out_dir+'/ensemble.pkl','wb') as fd:
      args.global_key=global_key
      dump((args,experiments,global_key),fd)

  if line:
    while stdin in select([stdin],[],[],0)[0]:
      stdin.readline()

