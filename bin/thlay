#!/usr/bin/env python
from argparse import ArgumentParser
ap=ArgumentParser()
ap.add_argument('mode',default='all',
                choices=['single','all','adaptive_lr','imbalances','unsw'])
ap.add_argument('--seed',default=20255202,type=int)

ap.add_argument('-lr_resolution',default=16,type=int)
ap.add_argument('-all_resolution',default=5,type=int)

ap.add_argument('-max_history_len',default=16384,type=int)

ap.add_argument('-reporting_interval',default=10,type=int)
ap.add_argument('-saving_interval',default=100,type=int)

ap.add_argument('-lr_init_min',default=1e-4,type=float)
ap.add_argument('-lr_init_max',default=1e-2,type=float)
ap.add_argument('-lr_min',default=1e-5,type=float)
ap.add_argument('-lr_max',default=1e-1,type=float)

ap.add_argument('-lr',default=1e-4,type=float)
ap.add_argument('-lr_update_interval',default=1000,type=int)
ap.add_argument('-lr_update_memory',default=1000,type=int)

ap.add_argument('-avg_rate',default=.1,type=float)#.01

ap.add_argument('-unsw_test',default='~/data/UNSW_NB15_testing-set.csv')
ap.add_argument('-unsw_train',default='~/data/UNSW_NB15_training-set.csv')

ap.add_argument('-model_inner_dims',default=[1024,256,4],type=int,nargs='+')

ap.add_argument('-bs',default=1,type=int)

ap.add_argument('-res',default=1000,type=int)

ap.add_argument('-outf',default='thlay')

ap.add_argument('-new',action='store_true')

ap.add_argument('-model_sigma_w',default=.3,type=float)
ap.add_argument('-model_sigma_b',default=0.,type=float)
ap.add_argument('-model_sqrt_normalise_w',action='store_true')
ap.add_argument('-glorot',action='store_true')
ap.add_argument('-uniform_b_0',action='store_true')
ap.add_argument('-model_resid',default=False,type=bool)

ap.add_argument('-p',default=.1,type=float)
ap.add_argument('-target_fp',default=.01,type=float)
ap.add_argument('-target_fn',default=.01,type=float)

#Silly
ap.add_argument('-lr_phase',default=0.,type=float)
ap.add_argument('-lr_momentum',default=0.05,type=float)
ap.add_argument('-lr_amplitude',default=0.,type=float)
ap.add_argument('-x_max',default=10.,type=float)

args=ap.parse_args()

from csv import writer
from pandas import read_csv
from types import SimpleNamespace
from pickle import load,dump
from time import perf_counter
from matplotlib.pyplot import title,imshow,legend,show,scatter,xlabel,ylabel,\
                              gca,plot,savefig,close
from matplotlib import colormaps
from matplotlib.patches import Patch
from matplotlib.cm import jet
from numpy import geomspace,prod
from jax.numpy import array,array_split,dot,vectorize,add,linspace,log,exp,eye,\
                      maximum,minimum,unique,concat,sin,zeros,sum as nsm
from jax.random import normal,key,uniform,split,choice
from jax.nn import tanh,softmax
from jax import grad
from jax.lax import scan
from sklearn.utils.extmath import cartesian
from sys import path,stdin
from os import mkdir
from select import select
from pathlib import Path
path.append(str(Path('.').absolute()))

f_to_str= lambda x,p=True:f'{x:.5g}'.ljust(10) if p else f'{x:.5g}'
exp_to_str=lambda e:'exp_p'+f_to_str(e.p,p=False)+'fpt'+f_to_str(e.target_fp,p=False)+\
                    'fnt'+f_to_str(e.target_fn,p=False)+'lr'+f_to_str(e.lr,p=False)


args.out_dir=args.outf+'_report'
try:
  mkdir(args.out_dir)
except FileExistsError:
  pass

if args.mode in ['single','imbalances','unsw']:
  lrs=array([args.lr])
elif args.mode=='adaptive_lr':
  lrs=geomspace(args.lr_init_min,args.lr_init_max,num=args.lr_resolution)
else:
  lrs=geomspace(args.lr_init_min,args.lr_init_max,num=args.all_resolution)

n_splits_img=100

#def act(x):return minimum(1,maximum(-1,x))
act=tanh

def f_unbatched(w,x,act=act):
  i=0
  while ('b',i) in w:
    x=act(x.dot(w[('w',i)])+w[('b',i)])
    i+=1
  return x
f=vectorize(f_unbatched,excluded=[0],signature='(m)->(n)')

def loss(w,x,y,U,V):
  y_smooth=f(w,x)
  #cts_fp=nsm(maximum(V-U,y_smooth)[~y])
  #cts_fn=nsm(maximum(U-V,-y_smooth)[y])
  #cts_fp=nsm(maximum(0,y_smooth)[~y])
  #cts_fn=nsm(maximum(0,-y_smooth)[y])
  #cts_fp=nsm((~y)*(y_smooth+.5))
  #cts_fn=nsm(y*(.5-y_smooth))
  cts_fp=nsm((y_smooth+1.)[~y])
  cts_fn=nsm((1.-y_smooth)[y])
  return U*cts_fp+V*cts_fn

dL=grad(loss)

def init_layers(sigma_w,sigma_b,layer_dimensions,key,resid=False,glorot=False):
  wb=[]
  n_steps=len(layer_dimensions)-1
  w_k=split(emit_key(),num=n_steps)
  b_k=split(emit_key(),num=n_steps)
  ret=dict()
  for i,(k,l,d_i,d_o) in enumerate(zip(w_k,b_k,layer_dimensions,layer_dimensions[1:])):
    if glorot:
      ret[('w',i)]=2*(6/(d_i+d_o))**.5*(uniform(shape=(d_i,d_o),key=k)-.5)
      ret[('b',i)]=zeros(shape=d_o)
    else:
      ret[('w',i)]=normal(shape=(d_i,d_o),key=k)
      ret[('b',i)]=normal(shape=d_o,key=l)
      ret[('w',i)]*=sigma_w
      ret[('b',i)]*=sigma_b
    if resid:
      ret[('w',i)]+=eye(*ret[('w',i)].shape)
  return ret

def sample_x(bs,key):
  return 2*args.x_max*uniform(shape=(bs,2),key=key)-args.x_max

global_key=key(args.seed)
def emit_key():
  global global_key
  global_key,child_key=split(global_key)
  return child_key

def size_rescale(l):
  return 25*(1+log(args.lr_max)-log(l))

def colour_rescale(fpfn):
  l=log(array(fpfn))-log(args.fpfn_min)
  l/=log(args.fpfn_max)-log(args.fpfn_min)
  return jet(l)

def mk_experiment(w_model_init,p,thresh,target_fp,target_fn,lr):
  e=SimpleNamespace()
  e.w_model=args.w_model_init.copy()

  e.lr=float(lr)
  e.size=size_rescale(lr) #for plotting
  e.p=float(p) #"imbalance"
  e.target_fp=target_fp
  e.target_fn=target_fn
  if args.mode=='all':
    e.colour=colour_rescale(target_fp/target_fn)
  e.fp=e.fn=.25

  e.U=e.V=1
  e.thresh=thresh
  e.history=SimpleNamespace(FP=[],FN=[],lr=[],cost=[],dw=[],resolution=1,l=0)
  return e

if args.new:
  print('Overwriting any existing ensembles...')
  mk_new=True
else:
  try:
    with open(args.out_dir+'/ensemble.pkl','rb') as fd:
      print('Opening experiment ensemble',args.outf,'...')
      od=args.out_dir #Correct the actual directory if opened somewhere else
      args,experiments,global_key=load(fd)
      args.out_dir=od
      mk_new=False
      global_key=args.global_key
      print('Restored',args.outf+'.pkl','from disk')
      mk_new=False
  except FileNotFoundError:
    print('No saved ensemble...')
    mk_new=True

if mk_new:
  print('Generating new ensemble...')
  
  args.global_key=global_key
  args.time_avgs=dict()
  args.target_shape=[2]+[16]*8+[1]

  if args.mode=='unsw':
    df_train=read_csv(args.unsw_train)
    df_test=read_csv(args.unsw_test)
    args.x_test=array(df_test[df_test.columns[(df_test.dtypes==int)|\
                                              (df_test.dtypes==float)]]).T[1:].T
    args.x_train=array(df_test[df_train.columns[(df_train.dtypes==int)|\
                                                (df_train.dtypes==float)]]).T[1:].T
    args.y_train=df_train['attack_cat']
    args.y_test=df_test['attack_cat']
    args.in_dim=len(args.x_train[0])
  else:
    args.in_dim=2

  args.target_sigma_w=.75
  args.target_sigma_b=2.
  
  args.w_target=init_layers(args.target_sigma_w,args.target_sigma_b,
                            args.target_shape,emit_key())
  #args.model_shape=[args.in_dim,256,256,4,1]
  args.model_shape=[args.in_dim]+args.model_inner_dims+[1]
  #args.model_shape=[args.in_dim,64,64,32,32,1]
  #args.model_shape=[args.in_dim,256,128,64,32,16,8,4,2,1]

  args.w_model_init=init_layers(args.model_sigma_w,args.model_sigma_b,args.model_shape,
                                resid=args.model_resid,glorot=args.glorot,key=emit_key())
  if args.model_sqrt_normalise_w:
    for i,l in enumerate(args.model_shape[:-1]):# was 1: - bug?!
      args.w_model_init[('w',i)]/=l**.5

  if args.uniform_b_0: #uniform biases
    args.w_model_init[('b',0)]=uniform(emit_key(),shape=args.model_shape[1])*\
                               2*args.x_max-args.x_max
  
  args.imbalance_min,args.imbalance_max=.01,.1
  if args.mode=='imbalances':
    args.imbalances=[args.imbalance_max,.02,args.imbalance_min]
    args.target_fps=[.15,.1,.05]
    args.target_fns=[.1]
  elif args.mode=='unsw':
    args.imbalances=(args.y_train.value_counts()+args.y_test.value_counts())/\
                    (len(df_train)+len(df_test))
    args.cats={float(p):s for p,s in\
               zip(args.imbalances,args.y_train.value_counts().index)}
    args.imbalances=args.imbalances[args.imbalances>.01] #Ignore really small p for now
    args.target_fps=[.15,.1,.05]
    args.target_fns=[.1]
  elif args.mode=='single':
    args.imbalances=[args.p]
    args.target_fps=[args.target_fp]
    args.target_fns=[args.target_fn]
  else:
    args.imbalances=geomspace(args.imbalance_max,args.imbalance_min,
                              num=args.all_resolution)

    args.target_fp_min,args.target_fp_max=.001,.01
    args.target_fps=geomspace(args.target_fp_min,args.target_fp_max,
                            num=args.all_resolution)
  
  if args.mode=='unsw':
    args.thresholds={float(p):0. for p in args.imbalances}
  else:
    print('Finding thresholds...')
    args.threshold_accuracy_tolerance=.01 #Within 1% of right value with high probability
    
    
    thresholding_sample_size=int(1/(args.threshold_accuracy_tolerance**2*\
                                    args.imbalance_min))
    x_thresholding=sample_x(thresholding_sample_size,emit_key())
    
    y_t_cts=f(args.w_target,x_thresholding).flatten()
    y_t_cts_sorted=y_t_cts.sort()
    args.thresholds={float(p):y_t_cts_sorted[-int(p*len(y_t_cts_sorted))]\
                    for p in args.imbalances}
    
    print('Imbalances and thresholds')
    for i,t in args.thresholds.items(): print(i,t)
  
  args.gamma1=.1#.01#.1#lr**1/3
  args.gamma2=.001#lr
  args.clock_avg_rate=.1
  args.loop_master_key=emit_key()
  args.step=0


  if args.mode=='all':
    args.fpfns=[a/b for a,b in zip(args.target_fps,args.target_fns)]
    args.fpfn_max,args.fpfn_min=args.fpfns[-1],args.fpfns[0]
    args.fpfn_colours=zip([colour_rescale(fpfn) for fpfn in args.fpfns],args.fpfns)
    colour_handles=[Patch(color=c,label=str(s)) for c,s in args.fpfn_colours]
  

  if args.mode=='all':
    args.targets=list(zip(args.target_fps,args.target_fns))
    experiments=[mk_experiment(args.w_model_init,p,thresh,target+fp,target_fn,lr)\
                 for (p,thresh) in args.imbalance_thresholds\
                 for (target_fp,target_fn) in args.targets\
                 for lr in lrs]
  elif args.mode=='single':
    experiments=[mk_experiment(args.w_model_init,.1,args.thresholds[.1],.01,.01,args.lr)]
  elif args.mode=='adaptive_lr':
    experiments=[mk_experiment(args.w_model_init,.1,args.thresholds[.1],.01,.01,lr) for\
                 lr in lrs]
  elif args.mode in ['imbalances','unsw']:
    experiments=[mk_experiment(args.w_model_init,float(p),
                               float(args.thresholds[float(p)]),
                               float(p*target_fp),float(p*target_fn),args.lr)\
                 for p in args.imbalances\
                 for target_fp in args.target_fps\
                 for target_fn in args.target_fns]


def get_timestep(label):
  global tl
  t=perf_counter()
  try: args.time_avgs[label]+=(1+args.clock_avg_rate)*args.clock_avg_rate*float(t-tl)
  except: args.time_avgs[label]=(1+args.clock_avg_rate)*float(t-tl)
  args.time_avgs[label]*=(1-args.clock_avg_rate)
  tl=t

while True:
  args.step+=1
  if not args.step%10:print(args.step)
  x=sample_x(args.bs,emit_key())
  y_t_cts=f(args.w_target,x).flatten()
  if args.mode=='unsw':
    batch_indices=choice(emit_key(),len(args.y_train),shape=(args.bs,))
    x=args.x_train[batch_indices]
    y_ts={float(p):array(args.y_train[batch_indices]==args.cats[p]) for\
          p in args.imbalances}
  else:
    y_ts={float(p):y_t_cts>thresh for p,thresh in args.thresholds.items()}

  args.lr_phase+=args.lr_momentum
  for e in experiments:

    if args.mode not in ['adaptive_lr','all']:
      e.lr=args.lr*exp(args.lr_amplitude*sin(args.lr_phase))
    e.y_t=y_ts[float(e.p)]
    e.bs=len(e.y_t)
    tl=perf_counter()
    y_p_cts=f(e.w_model,x).flatten()
    y_p=y_p_cts>0
    get_timestep('threshold')

    FP=int(nsm(y_p&(~e.y_t))) #Stop jax weirdness after ADC
    FN=int(nsm(e.y_t&(~y_p)))
    try:
      e.FPs[args.step%args.lr_update_memory]=FP
      e.FNs[args.step%args.lr_update_memory]=FN
    except AttributeError:
      e.FPs=[0]*args.lr_update_memory#[FP]*args.lr_update_interval
      e.FNs=[0]*args.lr_update_memory#[FN]*args.lr_update_interval
      e.FPs[args.step%args.lr_update_memory]=FP
      e.FNs[args.step%args.lr_update_memory]=FN
    window_div=min(args.step,args.lr_update_memory)
    e.fp_window=sum(e.FPs)/window_div
    e.fn_window=sum(e.FNs)/window_div
    e.cost_window=e.fp_window/e.target_fp+e.fn_window/e.target_fn
    if not args.step%e.history.resolution:
      e.history.FP.append(FP)
      e.history.FN.append(FN)
      e.history.lr.append(e.lr)
      e.history.cost.append(e.cost_window)
      e.history.l+=1
      args.max_history_len=16384
      if e.history.l>args.max_history_len:
        e.history.resolution*=2
        e.history.FP=[fp for i,fp in enumerate(e.history.FP) if i%2]
        e.history.FN=[fn for i,fn in enumerate(e.history.FN) if i%2]
        e.history.lr=[lr for i,lr in enumerate(e.history.lr) if i%2]
        e.history.cost=[c for i,c in enumerate(e.history.cost) if i%2]
        e.history.dw=[w for i,w in enumerate(e.history.dw) if i%2]
        e.history.l//=2


    e.fp_amnt=args.avg_rate*min(1,e.bs*e.fp)
    e.fn_amnt=args.avg_rate*min(1,e.bs*e.fn)
    e.fp*=(1-e.fp_amnt)
    e.fp+=e.fp_amnt*FP/e.bs
    e.fn*=(1-e.fn_amnt)
    e.fn+=e.fn_amnt*FN/e.bs

    #e.p_empirical*=(1-min(e.fp_amnt,e.fn_amnt))
    #e.p_empirical+=(1-min(e.fp_amnt,e.fn_amnt))*nsm(e.y_t)/e.bs
    #U,V=log(1+fp/target_fp),log(1+fn/target_fn)
    #U=u/(u+v)
    #V=v/(u+v)
    #U,V=softmax(array([gamma1*fp/target_fp,gamma1*fn/target_fn]))
    #U,V=softmax(array([fp/target_fp,fn/target_fn]))

    e.U,e.V=e.fp/e.target_fp,e.fn/e.target_fn
    e.V/=e.p #scale dfn with the imbalance
    nUV=(e.U**2+e.V**2)**.5
    e.U/=nUV
    e.V/=nUV
    get_timestep('U,V')

    upd=dL(e.w_model,x,e.y_t,e.U,e.V)
    get_timestep('dL')

    e.dw_l2=e.w_l2=0
    try:
      e.adam_M*=(1-args.gamma2)
      for k in upd:#Should apply to all bits simultaneously?
        e.adam_V[k]*=(1-args.gamma1)
        e.adam_V[k]+=args.gamma1*upd[k]
        e.adam_M+=args.gamma2*nsm(upd[k]**2)
    except AttributeError:
      print('Initialising adam weights...')
      e.adam_V=upd
      e.adam_M=sum([nsm(upd[k]**2) for k in upd])
    get_timestep('adam')
    for k in e.adam_V:
      delta=e.lr*e.adam_V[k]/(e.adam_M**.5+1e-8)
      e.w_model[k]-=delta
      ch_l2=nsm(delta**2)
      e.dw_l2+=ch_l2
      weight_l2=nsm(e.w_model[k]**2)
      e.w_l2+=weight_l2
    e.history.dw.append(e.dw_l2)
    get_timestep('updating')

    
  if not args.step%args.lr_update_interval and args.mode=='adaptive_lr':
    experiments=sorted(experiments,key=lambda x:x.cost_window)
    goodnesses=array([1/(1e-8+e.cost_window) for e in experiments])
    e_lr=v_lr=0.
    for e,g in zip(experiments,goodnesses):
      print('lr,un-normalised goodnesses=',e.lr,g)
      le_lr+=log(e.lr)/log(2)
      lv_lr+=(log(e.lr)/log(2))**2
    le_lr/=len(experiments)
    lv_lr/=len(experiments)
    lv_lr-=le_le**2
    print('E(log(lr)),V(log(lr))=',le_lr,lv_lr)
    goodnesses/=nsm(goodnesses)
    experiment_indices=array(range(len(experiments)))
    e=experiments[-1]
    parent=experiments[int(choice(emit_key(),experiment_indices,p=goodnesses))]
    e.lr=parent.lr
    w=lambda x,y,z:(x*z,y/z)
    if parent.lr>args.lr_max: rule=lambda x,y:(x,y*exp(-abs(normal(emit_key()))))
    elif parent.lr<args.lr_min: rule=lambda x,y:(x,y*exp(abs(normal(emit_key()))))
    else: rule=lambda x,y:w(x,y,exp(normal(emit_key())))
    parent.lr,e.lr=rule(parent.lr,e.lr)

    if uniform(emit_key())<e.cost_window/(1e-8+parent.cost_window)-1:
      print('Weight copying')
      e.w_model=parent.w_model.copy()
      e.adam_M=parent.adam_M.copy()
      e.adam_V=parent.adam_V.copy()
      e.fp=float(parent.fp)
      e.fn=float(parent.fn)
    lrs=array([e.lr for e in experiments])

  fd_tex=False
  line=''
  args.reporting_interval=10
  if not args.step%args.reporting_interval:

    print('|'.join([t.ljust(10) for t in ['p','target_fp','target_fn',
                                          'lr','fp','fn','w','dw','U','V']]))
    for e in experiments:
      print('|'.join([f_to_str(t) for t in [e.p,e.target_fp,e.target_fn,e.lr,
                                            e.fp,e.fn,e.w_l2,e.dw_l2,e.U,e.V]]))
    if stdin in select([stdin],[],[],0)[0]:
      line+=stdin.readline().lower()
      if ':' in line:
        line=line.split(':')

        if line[0]=='f':
          ty=float
        elif line[0]=='i':
          ty=int
        vars(args)[line[1]]=ty(line[2])
        print('args.'+line[1]+'<-'+str(ty(line[2])))
        line=''
      elif '?' in line:
        try:
          print(vars(args)[line.split('?')[0]])
        except KeyError:
          print('"',line.split('?')[0],'" not in args')
      elif '*' in line:
        print('args variables:')
        [print(v) for v in vars(args).keys()]
  if line:
    if 'x' in line:
      print('Bye!')
      exit()
    fp_perf=[]
    fn_perf=[]
    colours=[]
    sizes=[]
    if 'r' in line:
      line+='clis'
      args.report_dir=args.outf+'_report'
      fd_tex=open(args.outf+'_report/report.tex','w')
      print('\\documentclass[landscape]{article}\n'
            '\\usepackage[margin=0.7in]{geometry}\n'
            '\\usepackage[utf8]{inputenc}\n'
            '\\usepackage{graphicx}\n'
            '\\usepackage{float}\n'
            '\\usepackage{amsmath,amssymb,amsfonts,amsthm}\n'
            '\n'
            '\\title{Experiment ensemble report: '+args.mode+'}\n'
            '\\author{George Lee}\n'
            '\n'
            '\\begin{document}\n'
            '\\maketitle\n'
            'Report for ensemble labelled '+args.outf.replace('_','\\_')+'\n'
            '\\subsection{Performance after '+str(args.step)+' steps}',file=fd_tex)
      
      with open(args.out_dir+'/performance.csv','w') as fd_csv:
        w=writer(fd_csv)
        n_fps=len(args.target_fps)
        row=['imbalance','target_fps']+['']*(n_fps-1)+['target_fn','fps']+\
            ['']*(n_fps-1)+['fns']+['']*(n_fps-1)
        w.writerow(row)
        if fd_tex:
          conf_fill='r'*n_fps
          print('\\begin{tabular}{l|'+conf_fill+'|r|'+conf_fill+'|'+conf_fill+'}',
                file=fd_tex)
          print(' & '.join(row).replace('_',' ')+'\\\\',file=fd_tex)
          print('\\hline',file=fd_tex)
        n_imbalances=len(args.imbalances)
        for p in args.imbalances:
          tgt_fps=[]
          recent_fps=[]
          recent_fns=[]
          for e in [e for e in experiments if e.p==p]:
            tgt_fps.append(f_to_str(e.target_fp))
            fp_hist=e.history.FP[-int(10/e.p**2):]
            fn_hist=e.history.FN[-int(10/e.p**2):]
            recent_fps.append(f_to_str(sum(fp_hist)/(e.bs*len(fp_hist))))
            recent_fns.append(f_to_str(sum(fn_hist)/(e.bs*len(fn_hist))))
          row=[f_to_str(p)]+tgt_fps+[f_to_str(p/10)]+recent_fps+recent_fns
          w.writerow(row)
          if fd_tex:
            print('&'.join(row)+'\\\\',file=fd_tex)
    if fd_tex:
      print('\\end{tabular}\n'
            '\\subsection{Timing analysis of update step}\n'
            'Distinct steps in the algorithm taking on average:\\\\\n'
            '\\begin{tabular}{r|r}\n'
            'step&$\\log(\\overline{\\texttt{T}_\\texttt{step}})$\\\\\n',file=fd_tex)

    print('Timing:')
    for k,v in args.time_avgs.items():
      print(k,log(v)/log(2))
      if fd_tex: print('\\texttt{'+k+'}&'+f_to_str(log(v)/log(2))+'\\\\\n',file=fd_tex)
    if fd_tex: print('\\end{tabular}',file=fd_tex)

    if args.in_dim==2 and 'c' in line:
      if fd_tex:
        print('\\subsection{2d visualisation of classifications}',file=fd_tex)
        print('Here a 2d region is learned.\\\\',file=fd_tex)
        print('\n\\begin{figure}[H]',file=fd_tex)
        print('\\centering',file=fd_tex)
      for e in experiments:
        x=cartesian([linspace(-args.x_max,args.x_max,num=args.res)]*2)
        x_split=array_split(x,n_splits_img)
        y_t=concat([f(args.w_target,_x)>e.thresh for _x in x_split])\
            .reshape(args.res,args.res)
        y_p=concat([f(e.w_model,_x)>0 for _x in x_split])\
            .reshape(args.res,args.res)
        fp_img=(y_p&(~y_t))
        fn_img=((~y_p)&y_t)
        tp_img=(y_p&y_t)
        tn_img=(~(y_p|y_t))
        col_mat=[[1.,0,0],[0,1,0],[1,1,1],[0,0,0]]#fp,fn,tp,tn
        cols=array([fp_img,fn_img,tp_img,tn_img]).T.dot(array(col_mat))
        imshow(cols,extent=[-args.x_max,args.x_max]*2)
        legend(handles=[Patch(color=c,label=s) for c,s in\
                             zip(col_mat,['FP','FN','TP','TN'])])
        title('p='+str(e.p)+',target_fp='+str(e.target_fp)+\
              ',target_fn='+str(e.target_fn)+',lr='+str(e.lr))
        img_name=exp_to_str(e)+'.png'
        if fd_tex:
          savefig(args.report_dir+'/'+img_name)
          print('\n\\includegraphics[width=.3\\textwidth]{'+img_name+'}',file=fd_tex)
          close()
        else:
          show()

      if fd_tex:
        print('\\end{figure}',file=fd_tex)
      fp_perf.append(e.fp/e.target_fp)
      fn_perf.append(e.fn/e.target_fn)
      if args.mode=='all':
        colours.append(e.colour)
      else:
        colours=None

      sizes.append(e.size)
    if 'i' in line:
      model_desc='\n'.join(['Model shape:','->'.join([str(l) for l in args.model_shape]),
                            'Model initialisation parameters:',
                            '- matrix weight variance:'+\
                            f_to_str(args.model_sigma_w,p=False),
                            '- bias variance:'+f_to_str(args.model_sigma_b,p=False),
                            '- residual initialisation:'+\
                            f_to_str(args.model_resid,p=False),
                            '- matrix weight distribution:'+\
                            ('Glorot' if args.glorot else 'Normal'),
                            '- matrix dimension **-.5 normalisation:'+\
                            str(args.model_sqrt_normalise_w),
                            '- uniform first layer bias:'+str(args.uniform_b_0)])
      print(model_desc)
      if fd_tex:
        print('\\subsection{Model parameters}',file=fd_tex)
        print('Here the batch size was set to '+str(args.bs)+'.\\\\',file=fd_tex)
        print('\\texttt{'+(model_desc.replace('\n','}\\\\\n\\texttt{'))+'}\\\\',
              file=fd_tex)
    if 's' in line:
      sc=scatter(fp_perf,fn_perf,c=colours,s=sizes)
      lr_sizes=size_rescale(lrs)
      if args.mode=='all':
        cl=legend(handles=colour_handles,\
                  title='target_fp/target_fn',loc='upper right')
      #h=sc.legend_elements(prop="sizes",num=lr_sizes, alpha=0.6)[0]
      #legend(handles=h,labels=[str(r) for r in lrs],loc='lower right',title='lr')
      if args.mode=='all': gca().add_artist(cl)
      xlabel('fp/target_fp')
      ylabel('fn/target_fn')
      if fd_tex:
        savefig(args.report_dir+'/scatter.png')
        close()
        print('\\subsection{Comparing performance}',file=fd_tex)
        print('\n\\begin{figure}[H]',file=fd_tex)
        print('\\centering',file=fd_tex)
        print('\\includegraphics[width=.9\\textwidth]{scatter.png}',file=fd_tex)
        print('\\end{figure}',file=fd_tex)
      else:
        show()
    if 'l' in line:
      if fd_tex:
        print('\\subsection{Historical statistics}',file=fd_tex)
      get_cost=lambda e:e.history.cost
      get_lr=lambda e:e.history.lr
      get_dw=lambda e:e.history.dw
      for get_var,yl,desc in zip([get_cost,get_lr,get_dw],
                                    ['log(1e-8+fp/target_fp+fn/target_fn)','log(lr)',
                                     'log(dw)']
                                 ,['Loss','Learning_rate','Change_in_weights']):
        for e in experiments:
          arr=get_var(e)
          if args.mode=='unsw':
            lab='p='+f_to_str(e.p)+',target_fp='+f_to_str(e.target_fp)+\
                ',target_fn='+f_to_str(e.target_fp)
          else:
            lab=None
          #plot([log(arr[i]) for i in hist_indices],label=lab)
          plot([log(a)/log(2) for a in arr],label=lab)
        xlabel('Step number *'+str(e.history.resolution))
        ylabel(yl)
        title(desc.replace('_',' '))
        #legend(framealpha=0.2)
        if fd_tex:
          savefig(args.report_dir+'/'+desc+'.png')
          close()
          print('\n\\begin{figure}[H]',file=fd_tex)
          print('\\centering',file=fd_tex)
          print('\\includegraphics[width=.9\\textwidth]{'+desc+'.png}',file=fd_tex)
          print('\\end{figure}',file=fd_tex)
        else:
          show()

  if fd_tex:
    print('\\end{document}',file=fd_tex,flush=True)
    fd_tex.close()

  fd_tex=False
  if not args.step%args.saving_interval:
    with open(args.out_dir+'/ensemble.pkl','wb') as fd:
      args.global_key=global_key
      dump((args,experiments,global_key),fd)

  if line:
    while stdin in select([stdin],[],[],0)[0]:
      stdin.readline()

