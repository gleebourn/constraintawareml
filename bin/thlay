#!/usr/bin/env python
from argparse import ArgumentParser
ap=ArgumentParser()
ap.add_argument('mode',default='all',
                choices=['single','all','adaptive_lr','imbalances','unsw'])
ap.add_argument('--seed',default=20255202,type=int)

ap.add_argument('-lr_resolution',default=16,type=int)
ap.add_argument('-all_resolution',default=5,type=int)

ap.add_argument('-lr_init_min',default=1e-4,type=float)
ap.add_argument('-lr_init_max',default=1e-2,type=float)
ap.add_argument('-lr_min',default=1e-5,type=float)
ap.add_argument('-lr_max',default=1e-1,type=float)

ap.add_argument('-lr',default=1e-3,type=float)
ap.add_argument('-lr_update_interval',default=1000,type=int)
ap.add_argument('-lr_update_memory',default=1000,type=int)

ap.add_argument('-avg_rate',default=.1,type=float)#.01

ap.add_argument('-unsw_test',default='~/data/UNSW_NB15_testing-set.csv')
ap.add_argument('-unsw_train',default='~/data/UNSW_NB15_training-set.csv')

ap.add_argument('-bs',default=1,type=int)

ap.add_argument('-res',default=1000,type=int)

ap.add_argument('-outf',default='thlay')

ap.add_argument('-new',action='store_true')

ap.add_argument('-model_sigma_w',default=.3,type=float)
ap.add_argument('-model_sigma_b',default=0.,type=float)
ap.add_argument('-model_sqrt_normalise_w',action='store_true')
ap.add_argument('-glorot',action='store_true')
ap.add_argument('-uniform_b_0',default=True,type=bool)
ap.add_argument('-model_resid',default=False,type=bool)

#Silly
ap.add_argument('-lr_phase',default=0.,type=float)
ap.add_argument('-lr_momentum',default=0.05,type=float)
ap.add_argument('-lr_amplitude',default=0.,type=float)
ap.add_argument('-x_max',default=10.,type=float)

args=ap.parse_args()

from csv import writer
from pandas import read_csv
from types import SimpleNamespace
from pickle import load,dump
from time import perf_counter
from matplotlib.pyplot import title,imshow,legend,show,scatter,xlabel,ylabel,gca,plot
from matplotlib import colormaps
from matplotlib.patches import Patch
from matplotlib.cm import jet
from numpy import geomspace,prod
from jax.numpy import array,array_split,dot,vectorize,add,linspace,log,exp,eye,\
                      maximum,minimum,unique,concat,sin,zeros,sum as nsm
from jax.random import normal,key,uniform,split,choice
from jax.nn import tanh,softmax
from jax import grad
from jax.lax import scan
from sklearn.utils.extmath import cartesian
from sys import path,stdin
from select import select
from pathlib import Path
path.append(str(Path('.').absolute()))

f_to_str= lambda x:f'{x:.5g}'.ljust(10)

if args.mode in ['single','imbalances','unsw']:
  lrs=array([args.lr])
elif args.mode=='adaptive_lr':
  lrs=geomspace(args.lr_init_min,args.lr_init_max,num=args.lr_resolution)
else:
  lrs=geomspace(args.lr_init_min,args.lr_init_max,num=args.all_resolution)

n_splits_img=100

#def act(x):return minimum(1,maximum(-1,x))
act=tanh

def f_unbatched(w,x,act=act):
  i=0
  while ('b',i) in w:
    x=act(x.dot(w[('w',i)])+w[('b',i)])
    i+=1
  return x
f=vectorize(f_unbatched,excluded=[0],signature='(m)->(n)')

def loss(w,x,y,U,V):
  y_smooth=f(w,x)
  #cts_fp=nsm(maximum(V-U,y_smooth)[~y])
  #cts_fn=nsm(maximum(U-V,-y_smooth)[y])
  #cts_fp=nsm(maximum(0,y_smooth)[~y])
  #cts_fn=nsm(maximum(0,-y_smooth)[y])
  #cts_fp=nsm((~y)*(y_smooth+.5))
  #cts_fn=nsm(y*(.5-y_smooth))
  cts_fp=nsm((y_smooth+1.)[~y])
  cts_fn=nsm((1.-y_smooth)[y])
  return U*cts_fp+V*cts_fn

dL=grad(loss)

def init_layers(sigma_w,sigma_b,layer_dimensions,key,resid=False,glorot=False):
  wb=[]
  n_steps=len(layer_dimensions)-1
  w_k=split(emit_key(),num=n_steps)
  b_k=split(emit_key(),num=n_steps)
  ret=dict()
  for i,(k,l,d_i,d_o) in enumerate(zip(w_k,b_k,layer_dimensions,layer_dimensions[1:])):
    if glorot:
      ret[('w',i)]=2*(6/(d_i+d_o))**.5*(uniform(shape=(d_i,d_o),key=k)-.5)
      ret[('b',i)]=zeros(shape=d_o)
    else:
      ret[('w',i)]=normal(shape=(d_i,d_o),key=k)
      ret[('b',i)]=normal(shape=d_o,key=l)
      ret[('w',i)]*=sigma_w
      ret[('b',i)]*=sigma_b
    if resid:
      ret[('w',i)]+=eye(*ret[('w',i)].shape)
  return ret

def sample_x(bs,key):
  return 2*args.x_max*uniform(shape=(bs,2),key=key)-args.x_max

global_key=key(args.seed)
def emit_key():
  global global_key
  global_key,child_key=split(global_key)
  return child_key

def size_rescale(l):
  return 25*(1+log(args.lr_max)-log(l))

def colour_rescale(fpfn):
  l=log(array(fpfn))-log(args.fpfn_min)
  l/=log(args.fpfn_max)-log(args.fpfn_min)
  return jet(l)

def mk_experiment(w_model_init,p,thresh,target_fp,target_fn,lr):
  e=SimpleNamespace()
  e.w_model=args.w_model_init.copy()

  e.lr=float(lr)
  e.size=size_rescale(lr) #for plotting
  e.p=float(p) #"imbalance"
  e.target_fp=target_fp
  e.target_fn=target_fn
  if args.mode=='all':
    e.colour=colour_rescale(target_fp/target_fn)
  e.fp=e.fn=.25

  e.U=e.V=1
  e.thresh=thresh
  e.history=SimpleNamespace(FP=[],FN=[],lr=[],cost=[],dw=[])
  return e

if args.new:
  mk_new=True
else:
  try:
    with open(args.outf+'.pkl','rb') as fd:
      args,experiments,global_key=load(fd)
      mk_new=False
      global_key=args.global_key
      print('Restored',args.outf+'.pkl','from disk')
      mk_new=False
  except FileNotFoundError:
    mk_new=True

if mk_new:
  print('Generating new experiments...')
  
  args.global_key=global_key
  args.time_avgs=dict()
  args.target_shape=[2]+[16]*8+[1]

  if args.mode=='unsw':
    df_train=read_csv(args.unsw_train)
    df_test=read_csv(args.unsw_test)
    args.x_test=array(df_test[df_test.columns[(df_test.dtypes==int)|\
                                              (df_test.dtypes==float)]]).T[1:].T
    args.x_train=array(df_test[df_train.columns[(df_train.dtypes==int)|\
                                                (df_train.dtypes==float)]]).T[1:].T
    args.y_train=df_train['attack_cat']
    args.y_test=df_test['attack_cat']
    args.in_dim=len(args.x_train[0])
  else:
    args.in_dim=2

  args.target_sigma_w=.75
  args.target_sigma_b=2.
  
  args.w_target=init_layers(args.target_sigma_w,args.target_sigma_b,
                            args.target_shape,emit_key())
  #args.model_shape=[args.in_dim,256,256,4,1]
  args.model_shape=[args.in_dim,1024,256,4,1]
  #args.model_shape=[args.in_dim,64,64,32,32,1]
  #args.model_shape=[args.in_dim,256,128,64,32,16,8,4,2,1]

  args.w_model_init=init_layers(args.model_sigma_w,args.model_sigma_b,args.model_shape,
                                key=emit_key(),resid=args.model_resid,glorot=args.glorot)
  if args.model_sqrt_normalise_w:
    for i,l in enumerate(args.model_shape[:-1]):# was 1: - bug?!
      args.w_model_init[('w',i)]/=l**.5

  if args.uniform_b_0: #uniform biases
    args.w_model_init[('b',0)]=uniform(emit_key(),shape=args.model_shape[1])*\
                               2*args.x_max-args.x_max
  
  args.imbalance_min,args.imbalance_max=.01,.1
  if args.mode=='imbalances':
    args.imbalances=[args.imbalance_max,.02,args.imbalance_min]
    args.target_fps=[.15,.1,.05]
    args.target_fns=[.1]
  elif args.mode=='unsw':
    args.imbalances=(args.y_train.value_counts()+args.y_test.value_counts())/\
                    (len(df_train)+len(df_test))
    args.cats={float(p):s for p,s in\
               zip(args.imbalances,args.y_train.value_counts().index)}
    args.imbalances=args.imbalances[args.imbalances>.01] #Ignore really small p for now
    args.target_fps=[.15,.1,.05]
    args.target_fns=[.1]
  else:
    args.imbalances=geomspace(args.imbalance_max,args.imbalance_min,
                              num=args.all_resolution)

    args.target_fp_min,args.target_fp_max=.001,.01
    args.target_fps=geomspace(args.target_fp_min,args.target_fp_max,
                            num=args.all_resolution)
  
  if args.mode=='unsw':
    args.thresholds={float(p):0. for p in args.imbalances}
  else:
    print('Finding thresholds...')
    args.threshold_accuracy_tolerance=.01 #Within 1% of right value with high probability
    
    
    thresholding_sample_size=int(1/(args.threshold_accuracy_tolerance**2*\
                                    args.imbalance_min))
    x_thresholding=sample_x(thresholding_sample_size,emit_key())
    
    y_t_cts=f(args.w_target,x_thresholding).flatten()
    y_t_cts_sorted=y_t_cts.sort()
    args.thresholds={float(p):y_t_cts_sorted[-int(p*len(y_t_cts_sorted))]\
                    for p in args.imbalances}
    
    print('Imbalances and thresholds')
    for i,t in args.thresholds.items(): print(i,t)
  
  args.gamma1=.1#.01#.1#lr**1/3
  args.gamma2=.001#lr
  args.clock_avg_rate=.1
  args.loop_master_key=emit_key()
  args.step=0


  if args.mode=='all':
    args.fpfns=[a/b for a,b in zip(args.target_fps,args.target_fns)]
    args.fpfn_max,args.fpfn_min=args.fpfns[-1],args.fpfns[0]
    args.fpfn_colours=zip([colour_rescale(fpfn) for fpfn in args.fpfns],args.fpfns)
    colour_handles=[Patch(color=c,label=str(s)) for c,s in args.fpfn_colours]
  

  if args.mode=='all':
    args.targets=list(zip(args.target_fps,args.target_fns))
    experiments=[mk_experiment(args.w_model_init,p,thresh,target+fp,target_fn,lr)\
                 for (p,thresh) in args.imbalance_thresholds\
                 for (target_fp,target_fn) in args.targets\
                 for lr in lrs]
  elif args.mode=='single':
    experiments=[mk_experiment(args.w_model_init,.1,args.thresholds[.1],.01,.01,args.lr)]
  elif args.mode=='adaptive_lr':
    experiments=[mk_experiment(args.w_model_init,.1,args.thresholds[.1],.01,.01,lr) for\
                 lr in lrs]
  elif args.mode in ['imbalances','unsw']:
    experiments=[mk_experiment(args.w_model_init,float(p),
                               float(args.thresholds[float(p)]),
                               float(p*target_fp),float(p*target_fn),args.lr)\
                 for p in args.imbalances\
                 for target_fp in args.target_fps\
                 for target_fn in args.target_fns]


def get_timestep(label):
  global tl
  t=perf_counter()
  try: args.time_avgs[label]+=(1+args.clock_avg_rate)*args.clock_avg_rate*float(t-tl)
  except: args.time_avgs[label]=(1+args.clock_avg_rate)*float(t-tl)
  args.time_avgs[label]*=(1-args.clock_avg_rate)
  tl=t

while True:
  args.step+=1
  if not args.step%10:print(args.step)
  x=sample_x(args.bs,emit_key())
  y_t_cts=f(args.w_target,x).flatten()
  if args.mode=='unsw':
    batch_indices=choice(emit_key(),len(args.y_train),shape=(args.bs,))
    x=args.x_train[batch_indices]
    y_ts={float(p):array(args.y_train[batch_indices]==args.cats[p]) for p in args.imbalances}
  else:
    y_ts={float(p):y_t_cts>thresh for p,thresh in args.thresholds.items()}

  args.lr_phase+=args.lr_momentum
  for e in experiments:

    if args.mode not in ['adaptive_lr','all']:
      e.lr=args.lr*exp(args.lr_amplitude*sin(args.lr_phase))
    e.y_t=y_ts[float(e.p)]
    e.bs=len(e.y_t)
    tl=perf_counter()
    y_p_cts=f(e.w_model,x).flatten()
    y_p=y_p_cts>0
    get_timestep('threshold')

    FP=int(nsm(y_p&(~e.y_t))) #Stop jax weirdness after ADC
    FN=int(nsm(e.y_t&(~y_p)))
    try:
      e.FPs[args.step%args.lr_update_memory]=FP
      e.FNs[args.step%args.lr_update_memory]=FN
    except AttributeError:
      e.FPs=[0]*args.lr_update_memory#[FP]*args.lr_update_interval
      e.FNs=[0]*args.lr_update_memory#[FN]*args.lr_update_interval
      e.FPs[args.step%args.lr_update_memory]=FP
      e.FNs[args.step%args.lr_update_memory]=FN
    window_div=min(args.step,args.lr_update_memory)
    e.fp_window=sum(e.FPs)/window_div
    e.fn_window=sum(e.FNs)/window_div
    e.cost_window=e.fp_window/e.target_fp+e.fn_window/e.target_fn
    e.history.FP.append(FP)
    e.history.FN.append(FN)
    e.history.lr.append(e.lr)
    e.history.cost.append(e.cost_window)

    e.fp_amnt=args.avg_rate*min(1,e.bs*e.fp)
    e.fn_amnt=args.avg_rate*min(1,e.bs*e.fn)
    e.fp*=(1-e.fp_amnt)
    e.fp+=e.fp_amnt*FP/e.bs
    e.fn*=(1-e.fn_amnt)
    e.fn+=e.fn_amnt*FN/e.bs

    #e.p_empirical*=(1-min(e.fp_amnt,e.fn_amnt))
    #e.p_empirical+=(1-min(e.fp_amnt,e.fn_amnt))*nsm(e.y_t)/e.bs
    #U,V=log(1+fp/target_fp),log(1+fn/target_fn)
    #U=u/(u+v)
    #V=v/(u+v)
    #U,V=softmax(array([gamma1*fp/target_fp,gamma1*fn/target_fn]))
    #U,V=softmax(array([fp/target_fp,fn/target_fn]))

    e.U,e.V=e.fp/e.target_fp,e.fn/e.target_fn
    e.V/=e.p #scale dfn with the imbalance
    nUV=(e.U**2+e.V**2)**.5
    e.U/=nUV
    e.V/=nUV
    get_timestep('U,V')

    upd=dL(e.w_model,x,e.y_t,e.U,e.V)
    get_timestep('dL')

    e.dw_l2=e.w_l2=0
    try:
      e.adam_M*=(1-args.gamma2)
      for k in upd:#Should apply to all bits simultaneously?
        e.adam_V[k]*=(1-args.gamma1)
        e.adam_V[k]+=args.gamma1*upd[k]
        e.adam_M+=args.gamma2*nsm(upd[k]**2)
    except AttributeError:
      print('Initialising adam weights...')
      e.adam_V=upd
      e.adam_M=sum([nsm(upd[k]**2) for k in upd])
    get_timestep('adam')
    for k in e.adam_V:
      delta=e.lr*e.adam_V[k]/(e.adam_M**.5+1e-8)
      e.w_model[k]-=delta
      ch_l2=nsm(delta**2)
      e.dw_l2+=ch_l2
      weight_l2=nsm(e.w_model[k]**2)
      e.w_l2+=weight_l2
    e.history.dw.append(e.dw_l2)
    get_timestep('updating')

  if not args.step%args.lr_update_interval and args.mode=='adaptive_lr':
    experiments=sorted(experiments,key=lambda x:x.cost_window)
    try:
      goodnesses=array([1/e.cost_window for e in experiments])
    except ZeroDivisionError:
      print('!!!')
      goodnesses=array([1/(1e-8+e.cost_window) for e in experiments])
    e_lr=v_lr=0.
    for e,g in zip(experiments,goodnesses):
      print('lr,un-normalised goodnesses=',e.lr,g)
      le_lr+=log(e.lr)
      lv_lr+=log(e.lr)**2
    le_lr/=len(experiments)
    lv_lr/=len(experiments)
    lv_lr-=le_le**2
    print('E(log(lr)),V(log(lr))=',le_lr,lv_lr)
    goodnesses/=nsm(goodnesses)
    experiment_indices=array(range(len(experiments)))
    e=experiments[-1]
    parent=experiments[int(choice(emit_key(),experiment_indices,p=goodnesses))]
    e.lr=parent.lr
    print('Hi')
    w=lambda x,y,z:(x*z,y/z)
    if parent.lr>args.lr_max: rule=lambda x,y:(x,y*exp(-abs(normal(emit_key()))))
    elif parent.lr<args.lr_min: rule=lambda x,y:(x,y*exp(abs(normal(emit_key()))))
    else: rule=lambda x,y:w(x,y,exp(normal(emit_key())))
    parent.lr,e.lr=rule(parent.lr,e.lr)

    if uniform(emit_key())<e.cost_window/(1e-8+parent.cost_window)-1:
      print('Weight copying')
      e.w_model=parent.w_model.copy()
      e.adam_M=parent.adam_M.copy()
      e.adam_V=parent.adam_V.copy()
      e.fp=float(parent.fp)
      e.fn=float(parent.fn)
    lrs=array([e.lr for e in experiments])

  if not args.step%2:
    fp_perf=[]
    fn_perf=[]
    colours=[]
    sizes=[]
    if stdin in select([stdin],[],[],0)[0]:
      line=stdin.readline().lower()
      print('Timing:')
      for k,v in args.time_avgs.items():
        print(k,log(v))

      print('|'.join([t.ljust(10) for t in ['p','target_fp','target_fn',
                                            'lr','fp','fn','w','dw','U','V']]))
      for e in experiments:
        if stdin in select([stdin],[],[],0)[0] and 'x' in stdin.readline().lower():
          break

        if 'c' in line:
          if args.in_dim!=2:
            print('No 2d representation of input data!')
          else:
            x=cartesian([linspace(-args.x_max,args.x_max,num=args.res)]*2)
            x_split=array_split(x,n_splits_img)
            y_t=concat([f(args.w_target,_x)>e.thresh for _x in x_split])\
                .reshape(args.res,args.res)
            y_p=concat([f(e.w_model,_x)>0 for _x in x_split])\
                .reshape(args.res,args.res)
            fp_img=(y_p&(~y_t))
            fn_img=((~y_p)&y_t)
            tp_img=(y_p&y_t)
            tn_img=(~(y_p|y_t))
            col_mat=[[1.,0,0],[0,1,0],[1,1,1],[0,0,0]]#fp,fn,tp,tn
            cols=array([fp_img,fn_img,tp_img,tn_img]).T.dot(array(col_mat))
            imshow(cols,extent=[-args.x_max,args.x_max]*2)
            legend(handles=[Patch(color=c,label=s) for c,s in\
                                 zip(col_mat,['FP','FN','TP','TN'])])
            title('p='+str(e.p)+',target_fp='+str(e.target_fp)+\
                  ',target_fn='+str(e.target_fn)+',lr='+str(e.lr))
            show()

        fp_perf.append(e.fp/e.target_fp)
        fn_perf.append(e.fn/e.target_fn)
        if args.mode=='all':
          colours.append(e.colour)
        else:
          colours=None

        sizes.append(e.size)
        print('|'.join([f_to_str(t) for t in [e.p,e.target_fp,e.target_fn,e.lr,
                                              e.fp,e.fn,e.w_l2,e.dw_l2,e.U,e.V]]))
      print('Model shape:','->'.join([str(l) for l in args.model_shape]))
      if 's' in line:
        sc=scatter(fp_perf,fn_perf,c=colours,s=sizes)
        lr_sizes=size_rescale(lrs)
        if args.mode=='all':
          cl=legend(handles=colour_handles,\
                    title='target_fp/target_fn',loc='upper right')
        h=sc.legend_elements(prop="sizes",num=lr_sizes, alpha=0.6)[0]
        legend(handles=h,labels=[str(r) for r in lrs],loc='lower right',title='lr')
        if args.mode=='all': gca().add_artist(cl)
        xlabel('fp/target_fp')
        ylabel('fn/target_fn')
        show()
      if 'l' in line:
        hist_indices=range(args.step)
        if args.step>10000:
          t=args.step/10000
          hist_indices=[int(t*i) for i in range(10000)]
        else:
          t=1
          hist_indices=range(args.step)
        get_cost=lambda e:e.history.cost
        get_lr=lambda e:e.history.lr
        get_dw=lambda e:e.history.dw
        for get_var,yl,desc in zip([get_cost,get_lr,get_dw],
                                      ['log(1e-8+fp/target_fp+fn/target_fn)','log(lr)',
                                       'log(dw)']
                                   ,['Loss','Learning rate','Change in weights']):
          for e in experiments:
            arr=get_var(e)
            if args.mode=='unsw':
              lab='p='+f_to_str(e.p)+',target_fp='+f_to_str(e.target_fp)+\
                  ',target_fn='+f_to_str(e.target_fp)
            else:
              lab=None
            plot([log(arr[i]) for i in hist_indices],label=lab)
          xlabel('Step number *'+str(t))
          ylabel(yl)
          title(desc)
          #legend(framealpha=0.2)
          show()
      if 'x' in line:
        print('Bye!')
        exit()


      while stdin in select([stdin],[],[],0)[0]:
        stdin.readline()
      
  if not args.step%10:
    with open(args.outf+'.pkl','wb') as fd:
      args.global_key=global_key
      dump((args,experiments,global_key),fd)
    with open(args.outf+'.csv','w') as fd:
      w=writer(fd)
      w.writerow(['imbalance','target_fps','target_fn','fps','fns'])
      n_imbalances=len(args.imbalances)
      for p in args.imbalances:
        tgt_fps=[]
        recent_fps=[]
        recent_fns=[]
        for e in [e for e in experiments if e.p==p]:
          tgt_fps.append(f_to_str(e.target_fp))
          fp_hist=e.history.FP[-int(10/e.p**2):]
          fn_hist=e.history.FN[-int(10/e.p**2):]
          recent_fps.append(f_to_str(sum(fp_hist)/(e.bs*len(fp_hist))))
          recent_fns.append(f_to_str(sum(fn_hist)/(e.bs*len(fn_hist))))
        w.writerow([f_to_str(p),';'.join(tgt_fps),f_to_str(p/10),
                    ' '.join(recent_fps),';'.join(recent_fns)])

